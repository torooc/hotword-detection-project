{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "# import pydub\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "from scipy import signal as scipy_signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import datetime\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '/home/torooc/dataHDD2/speech_commands_v0.01/'\n",
    "\n",
    "run_name = 'runs/crnn_log_' + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_list_path = dataset_dir + 'testing_list.txt'\n",
    "validation_list_path = dataset_dir + 'validation_list.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(testing_list_path) as f:\n",
    "    testing_list = f.readlines()\n",
    "    testing_list = [file.strip() for file in testing_list]\n",
    "    \n",
    "with open(validation_list_path) as f:\n",
    "    validation_list = f.readlines()\n",
    "    validation_list = [file.strip() for file in validation_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_dirs = os.listdir(dataset_dir)\n",
    "\n",
    "command_dirs = [direc for direc in command_dirs if os.path.isdir(os.path.join(dataset_dir, direc))]\n",
    "\n",
    "command_dirs.sort()\n",
    "\n",
    "command_dirs.remove('_background_noise_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n"
     ]
    }
   ],
   "source": [
    "print(command_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "key2label_dict = dict()\n",
    "label2key_list = list()\n",
    "\n",
    "key2label_dict[' '] = 0\n",
    "label2key_list.append(' ')\n",
    "\n",
    "for i, command in enumerate(command_dirs):\n",
    "    key2label_dict[command] = i + 1\n",
    "    label2key_list.append(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " 'bed': 1,\n",
       " 'bird': 2,\n",
       " 'cat': 3,\n",
       " 'dog': 4,\n",
       " 'down': 5,\n",
       " 'eight': 6,\n",
       " 'five': 7,\n",
       " 'four': 8,\n",
       " 'go': 9,\n",
       " 'happy': 10,\n",
       " 'house': 11,\n",
       " 'left': 12,\n",
       " 'marvin': 13,\n",
       " 'nine': 14,\n",
       " 'no': 15,\n",
       " 'off': 16,\n",
       " 'on': 17,\n",
       " 'one': 18,\n",
       " 'right': 19,\n",
       " 'seven': 20,\n",
       " 'sheila': 21,\n",
       " 'six': 22,\n",
       " 'stop': 23,\n",
       " 'three': 24,\n",
       " 'tree': 25,\n",
       " 'two': 26,\n",
       " 'up': 27,\n",
       " 'wow': 28,\n",
       " 'yes': 29,\n",
       " 'zero': 30}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key2label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_wav_file_list = list()\n",
    "\n",
    "for command_dir in command_dirs:\n",
    "    wav_list = os.listdir(os.path.join(dataset_dir, command_dir))\n",
    "    \n",
    "    wav_list_with_prefix = [os.path.join(command_dir, file_name) for file_name in wav_list]\n",
    "    \n",
    "    total_wav_file_list += wav_list_with_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_list = list(set(total_wav_file_list) - set(testing_list) - set(validation_list))\n",
    "training_list.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvalidation_list\\ntesting_list\\ntraining_list\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "validation_list\n",
    "testing_list\n",
    "training_list\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audio_metadata = list()\n",
    "\n",
    "for wav_file_name in total_wav_file_list:\n",
    "    audio = AudioSegment.from_wav(dataset_dir + wav_file_name)\n",
    "    fs = audio.frame_rate\n",
    "    length_in_samples = audio.frame_count()\n",
    "    \n",
    "#   normalized_audio_array = np.asarray(audio.get_array_of_samples()) / 2 ** 15\n",
    "    \n",
    "#   print(\"Max: {}, Min: {}\".format(max(normalized_audio_array), min(normalized_audio_array)))\n",
    "    \n",
    "    audio_metadata.append([fs, length_in_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 16000\n",
    "\n",
    "class DatasetLoader():\n",
    "    \n",
    "    def __init__(self, batch_size, dataset_dir, wav_file_name_list, key2label, label2key):\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.wav_file_name_list = copy.deepcopy(wav_file_name_list)\n",
    "        self.sr = SR\n",
    "        self.nsc_in_ms = 40\n",
    "#         self.nov_in_ms = self.nsc_in_ms / 2\n",
    "        self.nov_in_ms = 0\n",
    "        self.nsc_in_sample = int(self.nsc_in_ms / 1000 * self.sr)\n",
    "        self.nov_in_sample = int(self.nov_in_ms / 1000 * self.sr)\n",
    "        \n",
    "        self.key2label = key2label\n",
    "        self.label2key = label2key\n",
    "        \n",
    "        self.spectrogram_list = list()\n",
    "        self.label_list = list()\n",
    "        \n",
    "        self.lock = threading.RLock()\n",
    "        \n",
    "        self.num_thread = 2\n",
    "        \n",
    "        self.loading_counter = 0\n",
    "        \n",
    "        self.dataset_number = len(self.wav_file_name_list)\n",
    "        \n",
    "    def shuffle_dataset_order(self):\n",
    "        random.shuffle(self.wav_file_name_list)\n",
    "        \n",
    "    def load_dataset(self):\n",
    "        \n",
    "        self.shuffle_dataset_order()\n",
    "        self.spectrogram_list = list()\n",
    "        self.label_list = list()\n",
    "        self.loading_counter = 0\n",
    "        \n",
    "        step = int(np.floor(self.dataset_number / self.num_thread))\n",
    "        \n",
    "        for i in range(self.num_thread):\n",
    "            \n",
    "            wav_file_name_list_thread = self.wav_file_name_list[i*step:(i+1)*step]\n",
    "            \n",
    "            if i + 1 == self.num_thread:\n",
    "                wav_file_name_list_thread = self.wav_file_name_list[i*step:]\n",
    "            \n",
    "            thread = threading.Thread(target=self.load_spectrogram, args=(wav_file_name_list_thread,))\n",
    "            thread.start()\n",
    "        \n",
    "    def batch_generator(self):\n",
    "        \n",
    "        self.load_dataset()\n",
    "        x = 0\n",
    "        \n",
    "        while self.loading_counter < self.dataset_number or len(self.spectrogram_list) > self.batch_size:\n",
    "            \n",
    "            if len(self.spectrogram_list) >= self.batch_size:\n",
    "\n",
    "                spectrogram_list = self.spectrogram_list[:self.batch_size]\n",
    "                label_list = self.label_list[:self.batch_size]\n",
    "\n",
    "                with self.lock:\n",
    "                    self.spectrogram_list = self.spectrogram_list[self.batch_size:]\n",
    "                    self.label_list = self.label_list[self.batch_size:]\n",
    "#                     print('[GPU Count: {}]'.format(x))\n",
    "#                     x += 1\n",
    "\n",
    "                spectrogram_time_step_list = [specgram.shape[1] for specgram in spectrogram_list]\n",
    "                max_time_step = max(spectrogram_time_step_list)\n",
    "                freq_size = spectrogram_list[0].shape[0]\n",
    "                batch = np.zeros([len(spectrogram_list), freq_size, max_time_step])\n",
    "\n",
    "                for j, specgram in enumerate(spectrogram_list):\n",
    "                    batch[j, :specgram.shape[0], :specgram.shape[1]] = specgram\n",
    "\n",
    "                batch_label = np.asarray(label_list)\n",
    "\n",
    "                yield batch, batch_label\n",
    "            \n",
    "            else:\n",
    "                time.sleep(0.05)\n",
    "        \n",
    "        \n",
    "        if len(self.spectrogram_list) > 0:\n",
    "\n",
    "            spectrogram_list = self.spectrogram_list\n",
    "            label_list = self.label_list\n",
    "\n",
    "            with self.lock:\n",
    "                self.spectrogram_list = self.spectrogram_list[self.batch_size:]\n",
    "                self.label_list = self.label_list[self.batch_size:]\n",
    "#                 print('[GPU Count: {}]'.format(x))\n",
    "#                 x += 1\n",
    "\n",
    "            spectrogram_time_step_list = [specgram.shape[1] for specgram in spectrogram_list]\n",
    "            max_time_step = max(spectrogram_time_step_list)\n",
    "            freq_size = spectrogram_list[0].shape[0]\n",
    "            batch = np.zeros([len(spectrogram_list), freq_size, max_time_step])\n",
    "\n",
    "            for j, specgram in enumerate(spectrogram_list):\n",
    "                batch[j, :specgram.shape[0], :specgram.shape[1]] = specgram\n",
    "\n",
    "            batch_label = np.asarray(label_list)\n",
    "\n",
    "            yield batch, batch_label\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "\n",
    "    def load_spectrogram(self, wav_file_name_list_part):\n",
    "\n",
    "        for i, wav_file_name in enumerate(wav_file_name_list_part):\n",
    "\n",
    "            audio = AudioSegment.from_wav(self.dataset_dir + wav_file_name)\n",
    "\n",
    "            normalized_audio_array = np.asarray(audio.get_array_of_samples()) / 2 ** 15\n",
    "\n",
    "            f, t, Zxx = scipy_signal.stft(normalized_audio_array, fs=self.sr, \n",
    "                                          nperseg=self.nsc_in_sample,\n",
    "                                          noverlap=self.nov_in_sample)\n",
    "\n",
    "            Sxx = np.abs(Zxx)\n",
    "\n",
    "            normalized_spectrogram = (20 * np.log10(np.maximum(Sxx, 1e-8)) + 160) / 160\n",
    "            \n",
    "            keyword = wav_file_name.split('/')[0]\n",
    "            label = self.key2label[keyword]\n",
    "            \n",
    "            with self.lock:\n",
    "                self.spectrogram_list.append(normalized_spectrogram)\n",
    "                self.label_list.append(label)\n",
    "                self.loading_counter += 1\n",
    "#                 print('[Dataset Count: {}] [Specgram Length: {}]'.format(self.loading_counter, len(self.spectrogram_list)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51088"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader_training = DatasetLoader(256, dataset_dir, training_list, key2label_dict, label2key_list)\n",
    "dataset_loader_testing = DatasetLoader(256, dataset_dir, testing_list, key2label_dict, label2key_list)\n",
    "dataset_loader_validation = DatasetLoader(256, dataset_dir, validation_list, key2label_dict, label2key_list)\n",
    "\n",
    "# dataset_loader_testing = DatasetLoader(64, dataset_dir, testing_list, key2label_dict, label2key_list)\n",
    "# dataset_loader_validation = DatasetLoader(64, dataset_dir, validation_list, key2label_dict, label2key_list)\n",
    "\n",
    "# dataset_loader_training = DatasetLoader(768, dataset_dir, training_list, key2label_dict, label2key_list)\n",
    "# dataset_loader_testing = DatasetLoader(768, dataset_dir, testing_list, key2label_dict, label2key_list)\n",
    "# dataset_loader_validation = DatasetLoader(768, dataset_dir, validation_list, key2label_dict, label2key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_generator = dataset_loader_training.batch_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class basic_model(nn.Module):\n",
    "#     def __init__(self, D_in, H, num_layers, num_labels):\n",
    "#         super(basic_model, self).__init__()\n",
    "#         self.fc = torch.nn.Linear(D_in, H)\n",
    "#         self.relu = torch.nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "#         self.gru_layers = nn.ModuleList([nn.GRU(H, int(H / 2), bidirectional=True, batch_first=True) for i in range(num_layers)])\n",
    "\n",
    "#         self.fc_pred = nn.Linear(H, num_labels)\n",
    "#         self.log_softmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "#     def forward(self, input_tensor):\n",
    "#         # (B, T, F)\n",
    "#         output_tensor = self.fc(input_tensor)\n",
    "#         output_tensor = self.relu(output_tensor)\n",
    "#         output_tensor = self.dropout(output_tensor)\n",
    "#         # (B, T, H)\n",
    "#         for layer in self.gru_layers:\n",
    "#             output_tensor, _ = layer(output_tensor)\n",
    "            \n",
    "#         output_tensor = self.fc_pred(output_tensor)\n",
    "\n",
    "#         output_tensor = self.log_softmax(output_tensor)\n",
    "        \n",
    "#         return output_tensor\n",
    "\n",
    "class basic_conv_model(nn.Module):\n",
    "#     def __init__(self, first_kernel_size, second_kernel_size, dropout_rate, num_labels):\n",
    "    def __init__(self):\n",
    "        super(basic_conv_model, self).__init__()\n",
    "        self.conv2d_1 = nn.Conv2d(1, 16, (13, 2))\n",
    "        self.conv2d_2 = nn.Conv2d(16, 32, (13, 2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(4800, 31)\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        input_tensor.unsqueeze_(1)\n",
    "        tensor = self.conv2d_1(input_tensor)\n",
    "#         print('[After 1st Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.dropout(tensor, 0.1, training=True)\n",
    "        tensor = F.max_pool2d(tensor, (3, 2))\n",
    "#         print('[After 1st maxpool2d]: {}'.format(tensor.shape))\n",
    "        tensor = self.conv2d_2(tensor)\n",
    "#         print('[After 2nd Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.dropout(tensor, 0.1, training=True)\n",
    "        tensor = F.max_pool2d(tensor, (3, 2))\n",
    "#         print('[After 2nd maxpool2d]: {}'.format(tensor.shape))\n",
    "        tensor = self.flatten(tensor)\n",
    "#         print('[After Flatten]: {}'.format(tensor.shape))\n",
    "        tensor = self.fc(tensor)\n",
    "#         print('[After fc]: {}'.format(tensor.shape))\n",
    "        pred_tensor = F.log_softmax(tensor, dim=-1)\n",
    "        \n",
    "        return pred_tensor\n",
    "    \n",
    "class basic_crnn_model(nn.Module):\n",
    "#     def __init__(self, first_kernel_size, second_kernel_size, dropout_rate, num_labels):\n",
    "    def __init__(self):\n",
    "        super(basic_crnn_model, self).__init__()\n",
    "        self.conv2d = nn.Conv2d(1, 16, (13, 2))\n",
    "        self.gru_1 = nn.GRU(16 * 103, 128, 1)\n",
    "        self.gru_2 = nn.GRU(128, 128, 1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(128 * 12, 31)\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        input_tensor.unsqueeze_(1)  # (B, 1, F, T)\n",
    "        tensor = self.conv2d(input_tensor) # (B, 16, F, T)\n",
    "#         print('[After 1st Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.dropout(tensor, 0.1, training=True)\n",
    "        tensor = F.max_pool2d(tensor, (3, 2))\n",
    "#         print('[After 1st maxpool2d]: {}'.format(tensor.shape))\n",
    "        \n",
    "        tensor = tensor.view(tensor.shape[0], -1, tensor.shape[3])\n",
    "        # (B, 16 * F, T)\n",
    "        \n",
    "#         print('[After Reshape]: {}'.format(tensor.shape))\n",
    "        \n",
    "        tensor.transpose_(0, 2) # (T, F, B)\n",
    "        tensor.transpose_(1, 2) # (T, B, F)\n",
    "\n",
    "        tensor, _ = self.gru_1(tensor)\n",
    "#         print('[After 2nd Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.dropout(tensor, 0.1, training=True) # (T, B, F)\n",
    "#         tensor = F.max_pool2d(tensor, (3, 2))\n",
    "#         print('[After 2nd maxpool2d]: {}'.format(tensor.shape))\n",
    "\n",
    "        tensor, _ = self.gru_2(tensor)\n",
    "#         print('[After 2nd Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.dropout(tensor, 0.1, training=True) # (T, B, F)\n",
    "\n",
    "        tensor.transpose_(0, 1) # (B, T, F)\n",
    "    \n",
    "#         print('[After Reshape]: {}'.format(tensor.shape))\n",
    "    \n",
    "        tensor = self.flatten(tensor)\n",
    "#         print('[After Flatten]: {}'.format(tensor.shape))\n",
    "        tensor = self.fc(tensor)\n",
    "#         print('[After fc]: {}'.format(tensor.shape))\n",
    "        pred_tensor = F.log_softmax(tensor, dim=-1)\n",
    "        \n",
    "        return pred_tensor\n",
    "\n",
    "    \n",
    "# model = basic_model(321, 512, 3, 31).float().to(device)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# dictation_loss = nn.CTCLoss().to(device)\n",
    "\n",
    "model = basic_crnn_model().float().to(device)  \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_generator = dataset_loader_training.batch_generator()\n",
    "# next(batch_generator)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:22:20.654475\n",
      "#000 [Train: 3.299] [Test: 3.067] [Valid: 3.033]\n",
      "#000 [Train: 0.075] [Test: 0.116] [Valid: 0.131]\n",
      "13:22:45.582481\n",
      "#001 [Train: 2.927] [Test: 2.813] [Valid: 2.755]\n",
      "#001 [Train: 0.144] [Test: 0.174] [Valid: 0.184]\n",
      "13:23:09.736561\n",
      "#002 [Train: 2.687] [Test: 2.618] [Valid: 2.550]\n",
      "#002 [Train: 0.203] [Test: 0.224] [Valid: 0.234]\n",
      "13:23:33.479940\n",
      "#003 [Train: 2.455] [Test: 2.391] [Valid: 2.321]\n",
      "#003 [Train: 0.270] [Test: 0.290] [Valid: 0.315]\n",
      "13:23:57.600702\n",
      "#004 [Train: 2.266] [Test: 2.227] [Valid: 2.166]\n",
      "#004 [Train: 0.329] [Test: 0.348] [Valid: 0.356]\n",
      "13:24:21.369490\n",
      "#005 [Train: 2.076] [Test: 2.038] [Valid: 1.984]\n",
      "#005 [Train: 0.386] [Test: 0.393] [Valid: 0.409]\n",
      "13:24:45.950329\n",
      "#006 [Train: 1.916] [Test: 1.896] [Valid: 1.843]\n",
      "#006 [Train: 0.434] [Test: 0.448] [Valid: 0.452]\n",
      "13:25:09.741968\n",
      "#007 [Train: 1.764] [Test: 1.755] [Valid: 1.714]\n",
      "#007 [Train: 0.481] [Test: 0.487] [Valid: 0.496]\n",
      "13:25:33.298441\n",
      "#008 [Train: 1.631] [Test: 1.637] [Valid: 1.597]\n",
      "#008 [Train: 0.521] [Test: 0.520] [Valid: 0.519]\n",
      "13:25:57.502656\n",
      "#009 [Train: 1.522] [Test: 1.519] [Valid: 1.474]\n",
      "#009 [Train: 0.554] [Test: 0.560] [Valid: 0.567]\n",
      "13:26:23.136587\n",
      "#010 [Train: 1.420] [Test: 1.426] [Valid: 1.389]\n",
      "#010 [Train: 0.586] [Test: 0.584] [Valid: 0.596]\n",
      "13:26:51.993881\n",
      "#011 [Train: 1.336] [Test: 1.362] [Valid: 1.320]\n",
      "#011 [Train: 0.608] [Test: 0.606] [Valid: 0.612]\n",
      "13:27:20.875611\n",
      "#012 [Train: 1.253] [Test: 1.271] [Valid: 1.240]\n",
      "#012 [Train: 0.636] [Test: 0.625] [Valid: 0.636]\n",
      "13:27:49.911813\n",
      "#013 [Train: 1.177] [Test: 1.224] [Valid: 1.182]\n",
      "#013 [Train: 0.658] [Test: 0.649] [Valid: 0.648]\n",
      "13:28:19.322933\n",
      "#014 [Train: 1.112] [Test: 1.158] [Valid: 1.126]\n",
      "#014 [Train: 0.678] [Test: 0.661] [Valid: 0.675]\n",
      "13:28:48.184501\n",
      "#015 [Train: 1.056] [Test: 1.117] [Valid: 1.081]\n",
      "#015 [Train: 0.691] [Test: 0.671] [Valid: 0.683]\n",
      "13:29:17.084795\n",
      "#016 [Train: 1.006] [Test: 1.047] [Valid: 1.015]\n",
      "#016 [Train: 0.709] [Test: 0.696] [Valid: 0.700]\n",
      "13:29:50.547693\n",
      "#017 [Train: 0.964] [Test: 0.994] [Valid: 0.985]\n",
      "#017 [Train: 0.720] [Test: 0.711] [Valid: 0.710]\n",
      "13:30:23.660460\n",
      "#018 [Train: 0.916] [Test: 0.961] [Valid: 0.942]\n",
      "#018 [Train: 0.735] [Test: 0.719] [Valid: 0.729]\n",
      "13:30:56.977355\n",
      "#019 [Train: 0.882] [Test: 0.951] [Valid: 0.922]\n",
      "#019 [Train: 0.744] [Test: 0.724] [Valid: 0.728]\n",
      "13:31:30.204513\n",
      "#020 [Train: 0.845] [Test: 0.928] [Valid: 0.901]\n",
      "#020 [Train: 0.753] [Test: 0.726] [Valid: 0.733]\n",
      "13:32:02.081533\n",
      "#021 [Train: 0.814] [Test: 0.873] [Valid: 0.857]\n",
      "#021 [Train: 0.763] [Test: 0.743] [Valid: 0.746]\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCH = 300\n",
    "\n",
    "writer = SummaryWriter(log_dir=run_name)\n",
    "\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    training_loss_list = list()\n",
    "    batch_generator = dataset_loader_training.batch_generator()\n",
    "    model.train()\n",
    "    \n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "\n",
    "    for (batch, label) in batch_generator:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(torch.cuda.FloatTensor(batch))\n",
    "        loss = F.nll_loss(pred, torch.cuda.LongTensor(label))\n",
    "        loss.backward()\n",
    "        training_loss_list.append(loss.item())\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, pred_label = torch.max(pred, 1)\n",
    "        correct_num += int((pred_label == torch.cuda.LongTensor(label)).sum().cpu().numpy())\n",
    "        total_num += len(label)\n",
    "        \n",
    "    acc_train = correct_num / total_num\n",
    "\n",
    "    testing_loss_list = list()\n",
    "\n",
    "    batch_generator = dataset_loader_testing.batch_generator()\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "\n",
    "    for (batch, label) in batch_generator:\n",
    "    #     optimizer.zero_grad()\n",
    "        pred = model(torch.cuda.FloatTensor(batch))\n",
    "        loss = F.nll_loss(pred, torch.cuda.LongTensor(label))\n",
    "#         loss.backward()\n",
    "        testing_loss_list.append(loss.item())\n",
    "    #     optimizer.step()\n",
    "    \n",
    "        _, pred_label = torch.max(pred, 1)\n",
    "        correct_num += int((pred_label == torch.cuda.LongTensor(label)).sum().cpu().numpy())\n",
    "        total_num += len(label)\n",
    "        \n",
    "    acc_test = correct_num / total_num\n",
    "\n",
    "    validation_loss_list = list()\n",
    "\n",
    "    batch_generator = dataset_loader_validation.batch_generator()\n",
    "    \n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "\n",
    "    for (batch, label) in batch_generator:\n",
    "    #     optimizer.zero_grad()\n",
    "        pred = model(torch.cuda.FloatTensor(batch))\n",
    "        loss = F.nll_loss(pred, torch.cuda.LongTensor(label))\n",
    "#         loss.backward()\n",
    "        validation_loss_list.append(loss.item())\n",
    "    #     optimizer.step()\n",
    "    \n",
    "        _, pred_label = torch.max(pred, 1)\n",
    "        correct_num += int((pred_label == torch.cuda.LongTensor(label)).sum().cpu().numpy())\n",
    "        total_num += len(label)\n",
    "        \n",
    "    acc_valid = correct_num / total_num\n",
    "    \n",
    "    training_loss_mean = np.mean(training_loss_list)\n",
    "    testing_loss_mean = np.mean(testing_loss_list)\n",
    "    validation_loss_mean = np.mean(validation_loss_list)\n",
    "    \n",
    "    print(datetime.datetime.now().time())\n",
    "    print('#{:03d} [Train: {:0.3f}] [Test: {:0.3f}] [Valid: {:0.3f}]'.format(epoch, training_loss_mean, testing_loss_mean, validation_loss_mean))\n",
    "    print('#{:03d} [Train: {:0.3f}] [Test: {:0.3f}] [Valid: {:0.3f}]'.format(epoch, acc_train, acc_test, acc_valid))\n",
    "    \n",
    "    writer.add_scalar('Loss/Train', training_loss_mean, epoch)\n",
    "    writer.add_scalar('Loss/Test', testing_loss_mean, epoch)\n",
    "    writer.add_scalar('Loss/Valid', validation_loss_mean, epoch)\n",
    "    writer.add_scalar('Acc/Train', acc_train, epoch)\n",
    "    writer.add_scalar('Acc/Test', acc_test, epoch)\n",
    "    writer.add_scalar('Acc/Valid', acc_valid, epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = model(torch.cuda.FloatTensor(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor(batch).unsqueeze_(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_tensor = torch.tensor(batch).to(device).float()\n",
    "# input_tensor = input_tensor.transpose(1, 2)\n",
    "# model(input_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for batch, label_list in batch_generator:\n",
    "#     print(batch.shape[0])\n",
    "#     plt.figure(figsize=(5, 1))\n",
    "#     plt.plot(label_list)\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.figure(figsize=(6, 18))\n",
    "# #     plt.imshow(batch[0], aspect='auto')\n",
    "#     plt.imshow(batch[0])\n",
    "#     plt.show()\n",
    "    \n",
    "#     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
