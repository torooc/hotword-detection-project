{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "# import pydub\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "from scipy import signal as scipy_signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import datetime\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '/home/torooc/dataHDD2/speech_commands_v0.01/'\n",
    "\n",
    "run_name = 'runs/rnn_8_layer' + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_list_path = dataset_dir + 'testing_list.txt'\n",
    "validation_list_path = dataset_dir + 'validation_list.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(testing_list_path) as f:\n",
    "    testing_list = f.readlines()\n",
    "    testing_list = [file.strip() for file in testing_list]\n",
    "    \n",
    "with open(validation_list_path) as f:\n",
    "    validation_list = f.readlines()\n",
    "    validation_list = [file.strip() for file in validation_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_dirs = os.listdir(dataset_dir)\n",
    "\n",
    "command_dirs = [direc for direc in command_dirs if os.path.isdir(os.path.join(dataset_dir, direc))]\n",
    "\n",
    "command_dirs.sort()\n",
    "\n",
    "command_dirs.remove('_background_noise_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n"
     ]
    }
   ],
   "source": [
    "print(command_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "key2label_dict = dict()\n",
    "label2key_list = list()\n",
    "\n",
    "key2label_dict[' '] = 0\n",
    "label2key_list.append(' ')\n",
    "\n",
    "for i, command in enumerate(command_dirs):\n",
    "    key2label_dict[command] = i + 1\n",
    "    label2key_list.append(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " 'bed': 1,\n",
       " 'bird': 2,\n",
       " 'cat': 3,\n",
       " 'dog': 4,\n",
       " 'down': 5,\n",
       " 'eight': 6,\n",
       " 'five': 7,\n",
       " 'four': 8,\n",
       " 'go': 9,\n",
       " 'happy': 10,\n",
       " 'house': 11,\n",
       " 'left': 12,\n",
       " 'marvin': 13,\n",
       " 'nine': 14,\n",
       " 'no': 15,\n",
       " 'off': 16,\n",
       " 'on': 17,\n",
       " 'one': 18,\n",
       " 'right': 19,\n",
       " 'seven': 20,\n",
       " 'sheila': 21,\n",
       " 'six': 22,\n",
       " 'stop': 23,\n",
       " 'three': 24,\n",
       " 'tree': 25,\n",
       " 'two': 26,\n",
       " 'up': 27,\n",
       " 'wow': 28,\n",
       " 'yes': 29,\n",
       " 'zero': 30}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key2label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_wav_file_list = list()\n",
    "\n",
    "for command_dir in command_dirs:\n",
    "    wav_list = os.listdir(os.path.join(dataset_dir, command_dir))\n",
    "    \n",
    "    wav_list_with_prefix = [os.path.join(command_dir, file_name) for file_name in wav_list]\n",
    "    \n",
    "    total_wav_file_list += wav_list_with_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_list = list(set(total_wav_file_list) - set(testing_list) - set(validation_list))\n",
    "training_list.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvalidation_list\\ntesting_list\\ntraining_list\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "validation_list\n",
    "testing_list\n",
    "training_list\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04c0d49712e463f845cfb89b2c9a070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=64721.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "audio_metadata = list()\n",
    "\n",
    "for wav_file_name in tqdm(total_wav_file_list):\n",
    "    audio = AudioSegment.from_wav(dataset_dir + wav_file_name)\n",
    "    fs = audio.frame_rate\n",
    "    length_in_samples = audio.frame_count()\n",
    "    \n",
    "#   normalized_audio_array = np.asarray(audio.get_array_of_samples()) / 2 ** 15\n",
    "    \n",
    "#   print(\"Max: {}, Min: {}\".format(max(normalized_audio_array), min(normalized_audio_array)))\n",
    "    \n",
    "    audio_metadata.append([fs, length_in_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 16000\n",
    "\n",
    "class DatasetLoader():\n",
    "    \n",
    "    def __init__(self, batch_size, dataset_dir, wav_file_name_list, key2label, label2key, is_train):\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.wav_file_name_list = copy.deepcopy(wav_file_name_list)\n",
    "        self.sr = SR\n",
    "        self.nsc_in_ms = 40\n",
    "#         self.nov_in_ms = self.nsc_in_ms / 2\n",
    "        self.nov_in_ms = 0\n",
    "        self.nsc_in_sample = int(self.nsc_in_ms / 1000 * self.sr)\n",
    "        self.nov_in_sample = int(self.nov_in_ms / 1000 * self.sr)\n",
    "        \n",
    "        self.key2label = key2label\n",
    "        self.label2key = label2key\n",
    "        \n",
    "        self.spectrogram_list = list()\n",
    "        self.label_list = list()\n",
    "        \n",
    "        self.lock = threading.RLock()\n",
    "        \n",
    "        self.num_thread = 4\n",
    "        \n",
    "        self.loading_counter = 0\n",
    "        \n",
    "        self.dataset_number = len(self.wav_file_name_list)\n",
    "        \n",
    "        self.is_train = is_train\n",
    "        \n",
    "    def shuffle_dataset_order(self):\n",
    "        random.shuffle(self.wav_file_name_list)\n",
    "        \n",
    "    def load_dataset(self):\n",
    "        \n",
    "        self.shuffle_dataset_order()\n",
    "        self.spectrogram_list = list()\n",
    "        self.label_list = list()\n",
    "        self.loading_counter = 0\n",
    "        \n",
    "        step = int(np.floor(self.dataset_number / self.num_thread))\n",
    "        \n",
    "        for i in range(self.num_thread):\n",
    "            \n",
    "            wav_file_name_list_thread = self.wav_file_name_list[i*step:(i+1)*step]\n",
    "            \n",
    "            if i + 1 == self.num_thread:\n",
    "                wav_file_name_list_thread = self.wav_file_name_list[i*step:]\n",
    "            \n",
    "            thread = threading.Thread(target=self.load_spectrogram, args=(wav_file_name_list_thread,))\n",
    "            thread.start()\n",
    "        \n",
    "    def batch_generator(self):\n",
    "        \n",
    "        self.load_dataset()\n",
    "        x = 0\n",
    "        \n",
    "        while self.loading_counter < self.dataset_number or len(self.spectrogram_list) > self.batch_size:\n",
    "            \n",
    "            if len(self.spectrogram_list) >= self.batch_size:\n",
    "\n",
    "                spectrogram_list = self.spectrogram_list[:self.batch_size]\n",
    "                label_list = self.label_list[:self.batch_size]\n",
    "\n",
    "                with self.lock:\n",
    "                    self.spectrogram_list = self.spectrogram_list[self.batch_size:]\n",
    "                    self.label_list = self.label_list[self.batch_size:]\n",
    "#                     print('[GPU Count: {}]'.format(x))\n",
    "#                     x += 1\n",
    "\n",
    "                spectrogram_time_step_list = [specgram.shape[1] for specgram in spectrogram_list]\n",
    "                max_time_step = max(spectrogram_time_step_list)\n",
    "                freq_size = spectrogram_list[0].shape[0]\n",
    "                batch = np.zeros([len(spectrogram_list), freq_size, max_time_step])\n",
    "\n",
    "                for j, specgram in enumerate(spectrogram_list):\n",
    "                    batch[j, :specgram.shape[0], :specgram.shape[1]] = specgram\n",
    "\n",
    "                batch_label = np.asarray(label_list)\n",
    "\n",
    "                yield batch, batch_label\n",
    "            \n",
    "            else:\n",
    "                time.sleep(0.05)\n",
    "        \n",
    "        \n",
    "        if len(self.spectrogram_list) > 0:\n",
    "\n",
    "            spectrogram_list = self.spectrogram_list\n",
    "            label_list = self.label_list\n",
    "\n",
    "            with self.lock:\n",
    "                self.spectrogram_list = self.spectrogram_list[self.batch_size:]\n",
    "                self.label_list = self.label_list[self.batch_size:]\n",
    "#                 print('[GPU Count: {}]'.format(x))\n",
    "#                 x += 1\n",
    "\n",
    "            spectrogram_time_step_list = [specgram.shape[1] for specgram in spectrogram_list]\n",
    "            max_time_step = max(spectrogram_time_step_list)\n",
    "            freq_size = spectrogram_list[0].shape[0]\n",
    "            batch = np.zeros([len(spectrogram_list), freq_size, max_time_step])\n",
    "\n",
    "            for j, specgram in enumerate(spectrogram_list):\n",
    "                batch[j, :specgram.shape[0], :specgram.shape[1]] = specgram\n",
    "\n",
    "            batch_label = np.asarray(label_list)\n",
    "\n",
    "            yield batch, batch_label\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "\n",
    "    def load_spectrogram(self, wav_file_name_list_part):\n",
    "\n",
    "        for i, wav_file_name in enumerate(wav_file_name_list_part):\n",
    "\n",
    "            audio = AudioSegment.from_wav(self.dataset_dir + wav_file_name)\n",
    "\n",
    "            normalized_audio_array = np.asarray(audio.get_array_of_samples()) / 2 ** 15\n",
    "\n",
    "            f, t, Zxx = scipy_signal.stft(normalized_audio_array, fs=self.sr, \n",
    "                                          nperseg=self.nsc_in_sample,\n",
    "                                          noverlap=self.nov_in_sample)\n",
    "\n",
    "            Sxx = np.abs(Zxx)\n",
    "\n",
    "            normalized_spectrogram = (20 * np.log10(np.maximum(Sxx, 1e-8)) + 160) / 160\n",
    "            \n",
    "            ###\n",
    "            if self.is_train:\n",
    "                normalized_spectrogram += (np.random.random(normalized_spectrogram.shape) - 0.5)/10\n",
    "                normalized_spectrogram = np.clip(normalized_spectrogram, 0, None)\n",
    "\n",
    "            ###\n",
    "            \n",
    "            keyword = wav_file_name.split('/')[0]\n",
    "            label = self.key2label[keyword]\n",
    "            \n",
    "            with self.lock:\n",
    "                self.spectrogram_list.append(normalized_spectrogram)\n",
    "                self.label_list.append(label)\n",
    "                self.loading_counter += 1\n",
    "#                 print('[Dataset Count: {}] [Specgram Length: {}]'.format(self.loading_counter, len(self.spectrogram_list)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51088"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_loader_training = DatasetLoader(256, dataset_dir, training_list, key2label_dict, label2key_list, True)\n",
    "# dataset_loader_testing = DatasetLoader(256, dataset_dir, testing_list, key2label_dict, label2key_list, False)\n",
    "# dataset_loader_validation = DatasetLoader(256, dataset_dir, validation_list, key2label_dict, label2key_list, False)\n",
    "\n",
    "# dataset_loader_testing = DatasetLoader(64, dataset_dir, testing_list, key2label_dict, label2key_list)\n",
    "# dataset_loader_validation = DatasetLoader(64, dataset_dir, validation_list, key2label_dict, label2key_list)\n",
    "\n",
    "# dataset_loader_training = DatasetLoader(512, dataset_dir, training_list, key2label_dict, label2key_list)\n",
    "# dataset_loader_testing = DatasetLoader(512, dataset_dir, testing_list, key2label_dict, label2key_list)\n",
    "# dataset_loader_validation = DatasetLoader(512, dataset_dir, validation_list, key2label_dict, label2key_list)\n",
    "\n",
    "dataset_loader_training = DatasetLoader(768, dataset_dir, training_list, key2label_dict, label2key_list, True)\n",
    "dataset_loader_testing = DatasetLoader(768, dataset_dir, testing_list, key2label_dict, label2key_list, False)\n",
    "dataset_loader_validation = DatasetLoader(768, dataset_dir, validation_list, key2label_dict, label2key_list, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_generator = dataset_loader_training.batch_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class basic_model(nn.Module):\n",
    "#     def __init__(self, D_in, H, num_layers, num_labels):\n",
    "#         super(basic_model, self).__init__()\n",
    "#         self.fc = torch.nn.Linear(D_in, H)\n",
    "#         self.relu = torch.nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "#         self.gru_layers = nn.ModuleList([nn.GRU(H, int(H / 2), bidirectional=True, batch_first=True) for i in range(num_layers)])\n",
    "\n",
    "#         self.fc_pred = nn.Linear(H, num_labels)\n",
    "#         self.log_softmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "#     def forward(self, input_tensor):\n",
    "#         # (B, T, F)\n",
    "#         output_tensor = self.fc(input_tensor)\n",
    "#         output_tensor = self.relu(output_tensor)\n",
    "#         output_tensor = self.dropout(output_tensor)\n",
    "#         # (B, T, H)\n",
    "#         for layer in self.gru_layers:\n",
    "#             output_tensor, _ = layer(output_tensor)\n",
    "            \n",
    "#         output_tensor = self.fc_pred(output_tensor)\n",
    "\n",
    "#         output_tensor = self.log_softmax(output_tensor)\n",
    "        \n",
    "#         return output_tensor\n",
    "\n",
    "class basic_conv_model(nn.Module):\n",
    "#     def __init__(self, first_kernel_size, second_kernel_size, dropout_rate, num_labels):\n",
    "    def __init__(self):\n",
    "        super(basic_conv_model, self).__init__()\n",
    "        self.conv2d_1 = nn.Conv2d(1, 16, (13, 2))\n",
    "        self.conv2d_2 = nn.Conv2d(16, 32, (13, 2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(4800, 31)\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        input_tensor.unsqueeze_(1)\n",
    "        tensor = self.conv2d_1(input_tensor)\n",
    "#         print('[After 1st Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.dropout(tensor, 0.1, training=True)\n",
    "        tensor = F.max_pool2d(tensor, (3, 2))\n",
    "#         print('[After 1st maxpool2d]: {}'.format(tensor.shape))\n",
    "        tensor = self.conv2d_2(tensor)\n",
    "#         print('[After 2nd Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.dropout(tensor, 0.1, training=True)\n",
    "        tensor = F.max_pool2d(tensor, (3, 2))\n",
    "#         print('[After 2nd maxpool2d]: {}'.format(tensor.shape))\n",
    "        tensor = self.flatten(tensor)\n",
    "#         print('[After Flatten]: {}'.format(tensor.shape))\n",
    "        tensor = self.fc(tensor)\n",
    "#         print('[After fc]: {}'.format(tensor.shape))\n",
    "        pred_tensor = F.log_softmax(tensor, dim=-1)\n",
    "        \n",
    "        return pred_tensor\n",
    "    \n",
    "class basic_crnn_model(nn.Module):\n",
    "#     def __init__(self, first_kernel_size, second_kernel_size, dropout_rate, num_labels):\n",
    "    def __init__(self):\n",
    "        super(basic_crnn_model, self).__init__()\n",
    "#         self.conv2d = nn.Conv2d(1, 128, (13, 2))\n",
    "        self.conv2d_1 = nn.Conv2d(1, 64, (7, 2))\n",
    "        self.conv2d_2 = nn.Conv2d(64, 64, (7, 2))\n",
    "#         self.gru_1 = nn.GRU(16 * 103, 256, 1)\n",
    "#         self.gru_1 = nn.GRU(128 * 103, 256, 1, bidirectional=True)\n",
    "#         self.gru_1 = nn.GRU(64 * 33, 256, 1, bidirectional=True)\n",
    "#         self.gru_1 = nn.GRU(64 * 99, 256, 1, bidirectional=True)\n",
    "        self.gru_1 = nn.GRU(19776, 256, 1, bidirectional=True)\n",
    "        self.gru_2 = nn.GRU(512, 256, 1, bidirectional=True)\n",
    "        self.gru_3 = nn.GRU(512, 256, 1, bidirectional=True)\n",
    "        self.gru_4 = nn.GRU(512, 256, 1, bidirectional=True)\n",
    "        self.flatten = nn.Flatten()\n",
    "#         self.fc = nn.Linear(256 * 2 * 12, 31)\n",
    "#         self.fc = nn.Linear(256 * 10, 31) # 5632\n",
    "        self.fc = nn.Linear(256 * 48, 31) # 12288\n",
    "#         self.fc = nn.Linear(256 * 22, 31)\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        input_tensor.unsqueeze_(1)  # (B, 1, F, T)\n",
    "        tensor = self.conv2d_1(input_tensor) # (B, 16, F, T)\n",
    "#         print('[After 1st Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "#         tensor = F.dropout(tensor, 0.1, training=True)\n",
    "#         tensor = F.max_pool2d(tensor, (3, 2))\n",
    "#         print('[After 1st maxpool2d]: {}'.format(tensor.shape))\n",
    "\n",
    "        tensor = self.conv2d_2(tensor) # (B, 16, F, T)\n",
    "# #         print('[After 1st Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "#         tensor = F.dropout(tensor, 0.1, training=True)\n",
    "#         tensor = F.max_pool2d(tensor, (3, 2))\n",
    "        \n",
    "        tensor = tensor.view(tensor.shape[0], -1, tensor.shape[3])\n",
    "        # (B, 16 * F, T)\n",
    "        \n",
    "#         print('[After Reshape]: {}'.format(tensor.shape))\n",
    "        \n",
    "        tensor.transpose_(0, 2) # (T, F, B)\n",
    "        tensor.transpose_(1, 2) # (T, B, F)\n",
    "\n",
    "        tensor, _ = self.gru_1(tensor)\n",
    "#         print('[After 2nd Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.dropout(tensor, 0.2, training=True) # (T, B, F)\n",
    "#         tensor = F.max_pool2d(tensor, (3, 2))\n",
    "#         print('[After 2nd maxpool2d]: {}'.format(tensor.shape))\n",
    "\n",
    "        tensor, _ = self.gru_2(tensor)\n",
    "#         print('[After 2nd Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.dropout(tensor, 0.2, training=True) # (T, B, F)\n",
    "        \n",
    "        tensor, _ = self.gru_3(tensor)\n",
    "#         print('[After 2nd Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.dropout(tensor, 0.2, training=True) # (T, B, F)\n",
    "        \n",
    "        tensor, _ = self.gru_4(tensor)\n",
    "#         print('[After 2nd Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.dropout(tensor, 0.2, training=True) # (T, B, F)\n",
    "\n",
    "        tensor.transpose_(0, 1) # (B, T, F)\n",
    "    \n",
    "#         print('[After Reshape]: {}'.format(tensor.shape))\n",
    "    \n",
    "        tensor = self.flatten(tensor)\n",
    "#         print('[After Flatten]: {}'.format(tensor.shape))\n",
    "        tensor = self.fc(tensor)\n",
    "#         print('[After fc]: {}'.format(tensor.shape))\n",
    "        pred_tensor = F.log_softmax(tensor, dim=-1)\n",
    "        \n",
    "        return pred_tensor\n",
    "    \n",
    "class basic_rnn_model(nn.Module):\n",
    "#     def __init__(self, first_kernel_size, second_kernel_size, dropout_rate, num_labels):\n",
    "    def __init__(self):\n",
    "        super(basic_rnn_model, self).__init__()\n",
    "        self.gru_1 = nn.GRU(321, 128, 1, bidirectional=True)\n",
    "        self.gru_2 = nn.GRU(256, 128, 1, bidirectional=True)\n",
    "        self.gru_3 = nn.GRU(256, 128, 1, bidirectional=True)\n",
    "        self.gru_4 = nn.GRU(256, 128, 1, bidirectional=True)\n",
    "        self.gru_5 = nn.GRU(256, 128, 1, bidirectional=True)\n",
    "        self.gru_6 = nn.GRU(256, 128, 1, bidirectional=True)\n",
    "        self.gru_7 = nn.GRU(256, 128, 1, bidirectional=True)\n",
    "        self.gru_8 = nn.GRU(256, 128, 1, bidirectional=True)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(256 * 26, 31)\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "#       input_tensor.unsqueeze_(1)\n",
    "        # (B, F, T)\n",
    "        input_tensor.transpose_(0, 2) # (T, F, B)\n",
    "        input_tensor.transpose_(1, 2) # (T, B, F)\n",
    "        tensor, _ = self.gru_1(input_tensor)\n",
    "#         print('[After 1st Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.dropout(tensor, 0.2, training=True)\n",
    "#         tensor = F.max_pool2d(tensor, (3, 2))\n",
    "#         print('[After 1st maxpool2d]: {}'.format(tensor.shape))\n",
    "        tensor, _ = self.gru_2(tensor)\n",
    "#         print('[After 2nd Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.dropout(tensor, 0.2, training=True)\n",
    "#         tensor = F.max_pool2d(tensor, (3, 2))\n",
    "#         print('[After 2nd maxpool2d]: {}'.format(tensor.shape))\n",
    "        tensor, _ = self.gru_3(tensor)\n",
    "#         print('[After 2nd Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.dropout(tensor, 0.2, training=True)\n",
    "        tensor, _ = self.gru_4(tensor)\n",
    "#         print('[After 2nd Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.dropout(tensor, 0.2, training=True)\n",
    "        \n",
    "        \n",
    "        tensor, _ = self.gru_5(tensor)\n",
    "#         print('[After 1st Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.dropout(tensor, 0.2, training=True)\n",
    "#         tensor = F.max_pool2d(tensor, (3, 2))\n",
    "#         print('[After 1st maxpool2d]: {}'.format(tensor.shape))\n",
    "        tensor, _ = self.gru_6(tensor)\n",
    "#         print('[After 2nd Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.dropout(tensor, 0.2, training=True)\n",
    "#         tensor = F.max_pool2d(tensor, (3, 2))\n",
    "#         print('[After 2nd maxpool2d]: {}'.format(tensor.shape))\n",
    "        tensor, _ = self.gru_7(tensor)\n",
    "#         print('[After 2nd Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.dropout(tensor, 0.2, training=True)\n",
    "        tensor, _ = self.gru_8(tensor)\n",
    "#         print('[After 2nd Conv2d]: {}'.format(tensor.shape))\n",
    "        tensor = F.relu(tensor)\n",
    "        tensor = F.dropout(tensor, 0.2, training=True)\n",
    "        \n",
    "        tensor.transpose_(0, 1) # (B, T, F)\n",
    "        tensor = self.flatten(tensor)\n",
    "#         print('[After Flatten]: {}'.format(tensor.shape))\n",
    "        tensor = self.fc(tensor)\n",
    "#         print('[After fc]: {}'.format(tensor.shape))\n",
    "        pred_tensor = F.log_softmax(tensor, dim=-1)\n",
    "        \n",
    "        return pred_tensor\n",
    "\n",
    "    \n",
    "# model = basic_model(321, 512, 3, 31).float().to(device)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# dictation_loss = nn.CTCLoss().to(device)\n",
    "\n",
    "# model = basic_crnn_model().float().to(device)  \n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hello_edge_fc_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(hello_edge_fc_model, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(8346, 31)\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        tensor = self.flatten(input_tensor)\n",
    "        tensor = self.fc(tensor)\n",
    "        pred_tensor = F.log_softmax(tensor, dim=-1)\n",
    "        \n",
    "        return pred_tensor\n",
    "    \n",
    "# model = basic_crnn_model().float().to(device)  \n",
    "model = basic_rnn_model().float().to(device)  \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_generator = dataset_loader_training.batch_generator()\n",
    "# next(batch_generator)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:02:41.048283\n",
      "#000 [Train: 3.406] [Test: 3.388] [Valid: 3.387]\n",
      "#000 [Train: 0.037] [Test: 0.042] [Valid: 0.049]\n",
      "15:03:09.181109\n",
      "#001 [Train: 3.177] [Test: 2.987] [Valid: 2.929]\n",
      "#001 [Train: 0.089] [Test: 0.119] [Valid: 0.135]\n",
      "15:03:37.695501\n",
      "#002 [Train: 2.914] [Test: 2.897] [Valid: 2.828]\n",
      "#002 [Train: 0.131] [Test: 0.129] [Valid: 0.140]\n",
      "15:04:05.947050\n",
      "#003 [Train: 2.780] [Test: 2.724] [Valid: 2.643]\n",
      "#003 [Train: 0.160] [Test: 0.171] [Valid: 0.195]\n",
      "15:04:34.270052\n",
      "#004 [Train: 2.653] [Test: 2.593] [Valid: 2.529]\n",
      "#004 [Train: 0.193] [Test: 0.208] [Valid: 0.224]\n",
      "15:05:02.871788\n",
      "#005 [Train: 2.523] [Test: 2.446] [Valid: 2.374]\n",
      "#005 [Train: 0.227] [Test: 0.261] [Valid: 0.277]\n",
      "15:05:31.266104\n",
      "#006 [Train: 2.357] [Test: 2.297] [Valid: 2.227]\n",
      "#006 [Train: 0.276] [Test: 0.304] [Valid: 0.323]\n",
      "15:05:59.710067\n",
      "#007 [Train: 2.210] [Test: 2.182] [Valid: 2.101]\n",
      "#007 [Train: 0.318] [Test: 0.344] [Valid: 0.357]\n",
      "15:06:27.808718\n",
      "#008 [Train: 2.091] [Test: 2.070] [Valid: 1.981]\n",
      "#008 [Train: 0.352] [Test: 0.376] [Valid: 0.387]\n",
      "15:06:56.283905\n",
      "#009 [Train: 1.974] [Test: 1.972] [Valid: 1.900]\n",
      "#009 [Train: 0.389] [Test: 0.406] [Valid: 0.420]\n",
      "15:07:24.624268\n",
      "#010 [Train: 1.869] [Test: 1.890] [Valid: 1.821]\n",
      "#010 [Train: 0.419] [Test: 0.424] [Valid: 0.434]\n",
      "15:07:53.256567\n",
      "#011 [Train: 1.754] [Test: 1.741] [Valid: 1.678]\n",
      "#011 [Train: 0.454] [Test: 0.463] [Valid: 0.478]\n",
      "15:08:21.784170\n",
      "#012 [Train: 1.658] [Test: 1.657] [Valid: 1.614]\n",
      "#012 [Train: 0.478] [Test: 0.482] [Valid: 0.504]\n",
      "15:08:49.810576\n",
      "#013 [Train: 1.566] [Test: 1.552] [Valid: 1.517]\n",
      "#013 [Train: 0.507] [Test: 0.519] [Valid: 0.522]\n",
      "15:09:18.474914\n",
      "#014 [Train: 1.479] [Test: 1.471] [Valid: 1.458]\n",
      "#014 [Train: 0.533] [Test: 0.539] [Valid: 0.536]\n",
      "15:09:47.027252\n",
      "#015 [Train: 1.405] [Test: 1.419] [Valid: 1.381]\n",
      "#015 [Train: 0.556] [Test: 0.559] [Valid: 0.571]\n",
      "15:10:15.672797\n",
      "#016 [Train: 1.335] [Test: 1.350] [Valid: 1.323]\n",
      "#016 [Train: 0.577] [Test: 0.576] [Valid: 0.580]\n",
      "15:10:44.064351\n",
      "#017 [Train: 1.267] [Test: 1.300] [Valid: 1.261]\n",
      "#017 [Train: 0.600] [Test: 0.596] [Valid: 0.598]\n",
      "15:11:12.855552\n",
      "#018 [Train: 1.212] [Test: 1.248] [Valid: 1.216]\n",
      "#018 [Train: 0.619] [Test: 0.612] [Valid: 0.612]\n",
      "15:11:41.459976\n",
      "#019 [Train: 1.148] [Test: 1.191] [Valid: 1.156]\n",
      "#019 [Train: 0.639] [Test: 0.632] [Valid: 0.643]\n",
      "15:12:10.140566\n",
      "#020 [Train: 1.102] [Test: 1.157] [Valid: 1.130]\n",
      "#020 [Train: 0.654] [Test: 0.645] [Valid: 0.645]\n",
      "15:12:38.940777\n",
      "#021 [Train: 1.048] [Test: 1.094] [Valid: 1.069]\n",
      "#021 [Train: 0.673] [Test: 0.663] [Valid: 0.675]\n",
      "15:13:07.285851\n",
      "#022 [Train: 1.000] [Test: 1.045] [Valid: 1.019]\n",
      "#022 [Train: 0.688] [Test: 0.673] [Valid: 0.686]\n",
      "15:13:36.073414\n",
      "#023 [Train: 0.959] [Test: 1.015] [Valid: 0.982]\n",
      "#023 [Train: 0.701] [Test: 0.688] [Valid: 0.696]\n",
      "15:14:04.747015\n",
      "#024 [Train: 0.923] [Test: 0.972] [Valid: 0.933]\n",
      "#024 [Train: 0.714] [Test: 0.701] [Valid: 0.717]\n",
      "15:14:33.517875\n",
      "#025 [Train: 0.880] [Test: 0.967] [Valid: 0.928]\n",
      "#025 [Train: 0.728] [Test: 0.701] [Valid: 0.713]\n",
      "15:15:02.108308\n",
      "#026 [Train: 0.855] [Test: 0.919] [Valid: 0.876]\n",
      "#026 [Train: 0.735] [Test: 0.721] [Valid: 0.734]\n",
      "15:15:30.696060\n",
      "#027 [Train: 0.823] [Test: 0.892] [Valid: 0.867]\n",
      "#027 [Train: 0.745] [Test: 0.726] [Valid: 0.732]\n",
      "15:15:59.413388\n",
      "#028 [Train: 0.797] [Test: 0.858] [Valid: 0.824]\n",
      "#028 [Train: 0.754] [Test: 0.737] [Valid: 0.748]\n",
      "15:16:28.393212\n",
      "#029 [Train: 0.768] [Test: 0.835] [Valid: 0.799]\n",
      "#029 [Train: 0.763] [Test: 0.745] [Valid: 0.755]\n",
      "15:16:57.180992\n",
      "#030 [Train: 0.744] [Test: 0.818] [Valid: 0.780]\n",
      "#030 [Train: 0.771] [Test: 0.752] [Valid: 0.762]\n",
      "15:17:25.895865\n",
      "#031 [Train: 0.723] [Test: 0.801] [Valid: 0.759]\n",
      "#031 [Train: 0.777] [Test: 0.755] [Valid: 0.771]\n",
      "15:17:54.767481\n",
      "#032 [Train: 0.700] [Test: 0.805] [Valid: 0.775]\n",
      "#032 [Train: 0.785] [Test: 0.755] [Valid: 0.762]\n",
      "15:18:23.485492\n",
      "#033 [Train: 0.679] [Test: 0.770] [Valid: 0.740]\n",
      "#033 [Train: 0.789] [Test: 0.767] [Valid: 0.773]\n",
      "15:18:52.482167\n",
      "#034 [Train: 0.664] [Test: 0.714] [Valid: 0.687]\n",
      "#034 [Train: 0.795] [Test: 0.789] [Valid: 0.792]\n",
      "15:19:21.677069\n",
      "#035 [Train: 0.647] [Test: 0.700] [Valid: 0.689]\n",
      "#035 [Train: 0.799] [Test: 0.794] [Valid: 0.794]\n",
      "15:19:50.164882\n",
      "#036 [Train: 0.628] [Test: 0.706] [Valid: 0.676]\n",
      "#036 [Train: 0.805] [Test: 0.787] [Valid: 0.798]\n",
      "15:20:19.146146\n",
      "#037 [Train: 0.617] [Test: 0.686] [Valid: 0.657]\n",
      "#037 [Train: 0.810] [Test: 0.784] [Valid: 0.802]\n",
      "15:20:47.923155\n",
      "#038 [Train: 0.595] [Test: 0.679] [Valid: 0.638]\n",
      "#038 [Train: 0.818] [Test: 0.796] [Valid: 0.807]\n",
      "15:21:16.712312\n",
      "#039 [Train: 0.579] [Test: 0.662] [Valid: 0.627]\n",
      "#039 [Train: 0.821] [Test: 0.801] [Valid: 0.810]\n",
      "15:21:45.614282\n",
      "#040 [Train: 0.572] [Test: 0.653] [Valid: 0.625]\n",
      "#040 [Train: 0.824] [Test: 0.803] [Valid: 0.813]\n",
      "15:22:14.758290\n",
      "#041 [Train: 0.552] [Test: 0.628] [Valid: 0.620]\n",
      "#041 [Train: 0.829] [Test: 0.806] [Valid: 0.812]\n",
      "15:22:44.083287\n",
      "#042 [Train: 0.545] [Test: 0.625] [Valid: 0.604]\n",
      "#042 [Train: 0.831] [Test: 0.816] [Valid: 0.818]\n",
      "15:23:13.304069\n",
      "#043 [Train: 0.532] [Test: 0.611] [Valid: 0.576]\n",
      "#043 [Train: 0.837] [Test: 0.818] [Valid: 0.827]\n",
      "15:23:53.924147\n",
      "#044 [Train: 0.519] [Test: 0.619] [Valid: 0.581]\n",
      "#044 [Train: 0.840] [Test: 0.815] [Valid: 0.822]\n",
      "15:24:25.588282\n",
      "#045 [Train: 0.508] [Test: 0.614] [Valid: 0.573]\n",
      "#045 [Train: 0.842] [Test: 0.818] [Valid: 0.823]\n",
      "15:25:04.515120\n",
      "#046 [Train: 0.502] [Test: 0.578] [Valid: 0.563]\n",
      "#046 [Train: 0.845] [Test: 0.828] [Valid: 0.828]\n",
      "15:25:32.958857\n",
      "#047 [Train: 0.493] [Test: 0.558] [Valid: 0.545]\n",
      "#047 [Train: 0.847] [Test: 0.836] [Valid: 0.833]\n",
      "15:26:01.985466\n",
      "#048 [Train: 0.477] [Test: 0.578] [Valid: 0.565]\n",
      "#048 [Train: 0.852] [Test: 0.829] [Valid: 0.829]\n",
      "15:26:30.363926\n",
      "#049 [Train: 0.469] [Test: 0.576] [Valid: 0.532]\n",
      "#049 [Train: 0.855] [Test: 0.830] [Valid: 0.839]\n",
      "15:26:58.726442\n",
      "#050 [Train: 0.469] [Test: 0.562] [Valid: 0.529]\n",
      "#050 [Train: 0.856] [Test: 0.832] [Valid: 0.841]\n",
      "15:27:27.255816\n",
      "#051 [Train: 0.451] [Test: 0.556] [Valid: 0.536]\n",
      "#051 [Train: 0.861] [Test: 0.836] [Valid: 0.840]\n",
      "15:27:56.757638\n",
      "#052 [Train: 0.447] [Test: 0.551] [Valid: 0.524]\n",
      "#052 [Train: 0.862] [Test: 0.837] [Valid: 0.841]\n",
      "15:28:25.647472\n",
      "#053 [Train: 0.437] [Test: 0.535] [Valid: 0.524]\n",
      "#053 [Train: 0.865] [Test: 0.837] [Valid: 0.838]\n",
      "15:28:55.840956\n",
      "#054 [Train: 0.431] [Test: 0.533] [Valid: 0.500]\n",
      "#054 [Train: 0.867] [Test: 0.840] [Valid: 0.849]\n",
      "15:29:25.171184\n",
      "#055 [Train: 0.427] [Test: 0.501] [Valid: 0.502]\n",
      "#055 [Train: 0.867] [Test: 0.857] [Valid: 0.846]\n",
      "15:29:53.677374\n",
      "#056 [Train: 0.414] [Test: 0.533] [Valid: 0.496]\n",
      "#056 [Train: 0.871] [Test: 0.846] [Valid: 0.851]\n",
      "15:30:22.815458\n",
      "#057 [Train: 0.410] [Test: 0.509] [Valid: 0.480]\n",
      "#057 [Train: 0.873] [Test: 0.848] [Valid: 0.853]\n",
      "15:30:51.429050\n",
      "#058 [Train: 0.401] [Test: 0.501] [Valid: 0.493]\n",
      "#058 [Train: 0.877] [Test: 0.853] [Valid: 0.855]\n",
      "15:31:20.559272\n",
      "#059 [Train: 0.403] [Test: 0.501] [Valid: 0.488]\n",
      "#059 [Train: 0.875] [Test: 0.849] [Valid: 0.851]\n",
      "15:31:50.121045\n",
      "#060 [Train: 0.394] [Test: 0.503] [Valid: 0.478]\n",
      "#060 [Train: 0.877] [Test: 0.849] [Valid: 0.860]\n",
      "15:32:18.515532\n",
      "#061 [Train: 0.384] [Test: 0.488] [Valid: 0.469]\n",
      "#061 [Train: 0.881] [Test: 0.854] [Valid: 0.858]\n",
      "15:32:47.649570\n",
      "#062 [Train: 0.381] [Test: 0.489] [Valid: 0.467]\n",
      "#062 [Train: 0.880] [Test: 0.856] [Valid: 0.861]\n",
      "15:33:16.065627\n",
      "#063 [Train: 0.380] [Test: 0.494] [Valid: 0.470]\n",
      "#063 [Train: 0.881] [Test: 0.853] [Valid: 0.862]\n",
      "15:33:45.558823\n",
      "#064 [Train: 0.371] [Test: 0.476] [Valid: 0.462]\n",
      "#064 [Train: 0.885] [Test: 0.860] [Valid: 0.859]\n",
      "15:34:14.233167\n",
      "#065 [Train: 0.366] [Test: 0.462] [Valid: 0.452]\n",
      "#065 [Train: 0.887] [Test: 0.864] [Valid: 0.861]\n",
      "15:34:43.701424\n",
      "#066 [Train: 0.359] [Test: 0.480] [Valid: 0.461]\n",
      "#066 [Train: 0.888] [Test: 0.859] [Valid: 0.861]\n",
      "15:35:12.347772\n",
      "#067 [Train: 0.349] [Test: 0.469] [Valid: 0.447]\n",
      "#067 [Train: 0.891] [Test: 0.861] [Valid: 0.863]\n",
      "15:35:42.311469\n",
      "#068 [Train: 0.351] [Test: 0.460] [Valid: 0.444]\n",
      "#068 [Train: 0.890] [Test: 0.863] [Valid: 0.865]\n",
      "15:36:11.907159\n",
      "#069 [Train: 0.345] [Test: 0.459] [Valid: 0.441]\n",
      "#069 [Train: 0.892] [Test: 0.867] [Valid: 0.868]\n",
      "15:36:41.011732\n",
      "#070 [Train: 0.339] [Test: 0.448] [Valid: 0.449]\n",
      "#070 [Train: 0.894] [Test: 0.866] [Valid: 0.867]\n",
      "15:37:10.380493\n",
      "#071 [Train: 0.338] [Test: 0.446] [Valid: 0.429]\n",
      "#071 [Train: 0.894] [Test: 0.869] [Valid: 0.872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:37:40.305261\n",
      "#072 [Train: 0.333] [Test: 0.450] [Valid: 0.426]\n",
      "#072 [Train: 0.895] [Test: 0.868] [Valid: 0.872]\n",
      "15:38:09.222801\n",
      "#073 [Train: 0.320] [Test: 0.445] [Valid: 0.433]\n",
      "#073 [Train: 0.901] [Test: 0.871] [Valid: 0.872]\n",
      "15:38:38.754557\n",
      "#074 [Train: 0.318] [Test: 0.454] [Valid: 0.439]\n",
      "#074 [Train: 0.901] [Test: 0.866] [Valid: 0.869]\n",
      "15:39:08.428136\n",
      "#075 [Train: 0.316] [Test: 0.450] [Valid: 0.434]\n",
      "#075 [Train: 0.902] [Test: 0.870] [Valid: 0.869]\n",
      "15:39:37.122422\n",
      "#076 [Train: 0.313] [Test: 0.428] [Valid: 0.415]\n",
      "#076 [Train: 0.902] [Test: 0.875] [Valid: 0.876]\n",
      "15:40:06.420352\n",
      "#077 [Train: 0.307] [Test: 0.428] [Valid: 0.414]\n",
      "#077 [Train: 0.904] [Test: 0.875] [Valid: 0.875]\n",
      "15:40:36.108905\n",
      "#078 [Train: 0.304] [Test: 0.439] [Valid: 0.432]\n",
      "#078 [Train: 0.906] [Test: 0.873] [Valid: 0.871]\n",
      "15:41:04.749603\n",
      "#079 [Train: 0.304] [Test: 0.423] [Valid: 0.414]\n",
      "#079 [Train: 0.904] [Test: 0.876] [Valid: 0.880]\n",
      "15:41:34.411047\n",
      "#080 [Train: 0.298] [Test: 0.425] [Valid: 0.412]\n",
      "#080 [Train: 0.906] [Test: 0.878] [Valid: 0.880]\n",
      "15:42:03.119657\n",
      "#081 [Train: 0.288] [Test: 0.423] [Valid: 0.406]\n",
      "#081 [Train: 0.910] [Test: 0.877] [Valid: 0.881]\n",
      "15:42:32.016569\n",
      "#082 [Train: 0.295] [Test: 0.427] [Valid: 0.411]\n",
      "#082 [Train: 0.908] [Test: 0.877] [Valid: 0.877]\n",
      "15:43:02.276350\n",
      "#083 [Train: 0.286] [Test: 0.414] [Valid: 0.392]\n",
      "#083 [Train: 0.910] [Test: 0.881] [Valid: 0.883]\n",
      "15:43:31.872443\n",
      "#084 [Train: 0.280] [Test: 0.413] [Valid: 0.396]\n",
      "#084 [Train: 0.912] [Test: 0.880] [Valid: 0.881]\n",
      "15:44:00.865753\n",
      "#085 [Train: 0.281] [Test: 0.415] [Valid: 0.400]\n",
      "#085 [Train: 0.912] [Test: 0.879] [Valid: 0.882]\n",
      "15:44:30.360575\n",
      "#086 [Train: 0.274] [Test: 0.418] [Valid: 0.404]\n",
      "#086 [Train: 0.914] [Test: 0.878] [Valid: 0.878]\n",
      "15:44:59.920221\n",
      "#087 [Train: 0.275] [Test: 0.394] [Valid: 0.389]\n",
      "#087 [Train: 0.913] [Test: 0.888] [Valid: 0.883]\n",
      "15:45:28.663327\n",
      "#088 [Train: 0.272] [Test: 0.393] [Valid: 0.402]\n",
      "#088 [Train: 0.916] [Test: 0.886] [Valid: 0.879]\n",
      "15:45:58.445391\n",
      "#089 [Train: 0.267] [Test: 0.409] [Valid: 0.396]\n",
      "#089 [Train: 0.917] [Test: 0.884] [Valid: 0.884]\n",
      "15:46:28.131795\n",
      "#090 [Train: 0.263] [Test: 0.389] [Valid: 0.375]\n",
      "#090 [Train: 0.918] [Test: 0.888] [Valid: 0.892]\n",
      "15:46:57.491622\n",
      "#091 [Train: 0.262] [Test: 0.405] [Valid: 0.387]\n",
      "#091 [Train: 0.917] [Test: 0.884] [Valid: 0.883]\n",
      "15:47:27.273116\n",
      "#092 [Train: 0.257] [Test: 0.423] [Valid: 0.403]\n",
      "#092 [Train: 0.919] [Test: 0.878] [Valid: 0.879]\n",
      "15:47:56.572365\n",
      "#093 [Train: 0.257] [Test: 0.396] [Valid: 0.389]\n",
      "#093 [Train: 0.919] [Test: 0.888] [Valid: 0.886]\n",
      "15:48:25.834367\n",
      "#094 [Train: 0.254] [Test: 0.379] [Valid: 0.395]\n",
      "#094 [Train: 0.919] [Test: 0.885] [Valid: 0.883]\n",
      "15:48:55.591979\n",
      "#095 [Train: 0.252] [Test: 0.385] [Valid: 0.399]\n",
      "#095 [Train: 0.921] [Test: 0.887] [Valid: 0.882]\n",
      "15:49:24.811463\n",
      "#096 [Train: 0.250] [Test: 0.396] [Valid: 0.381]\n",
      "#096 [Train: 0.921] [Test: 0.888] [Valid: 0.887]\n",
      "15:49:54.521840\n",
      "#097 [Train: 0.241] [Test: 0.392] [Valid: 0.386]\n",
      "#097 [Train: 0.924] [Test: 0.884] [Valid: 0.886]\n",
      "15:50:24.277809\n",
      "#098 [Train: 0.243] [Test: 0.388] [Valid: 0.391]\n",
      "#098 [Train: 0.924] [Test: 0.889] [Valid: 0.885]\n",
      "15:50:53.003841\n",
      "#099 [Train: 0.239] [Test: 0.374] [Valid: 0.367]\n",
      "#099 [Train: 0.926] [Test: 0.891] [Valid: 0.889]\n",
      "15:51:23.036421\n",
      "#100 [Train: 0.234] [Test: 0.385] [Valid: 0.373]\n",
      "#100 [Train: 0.927] [Test: 0.891] [Valid: 0.890]\n",
      "15:51:52.797238\n",
      "#101 [Train: 0.231] [Test: 0.383] [Valid: 0.366]\n",
      "#101 [Train: 0.928] [Test: 0.891] [Valid: 0.891]\n",
      "15:52:22.601985\n",
      "#102 [Train: 0.231] [Test: 0.383] [Valid: 0.361]\n",
      "#102 [Train: 0.928] [Test: 0.890] [Valid: 0.892]\n",
      "15:53:07.786957\n",
      "#103 [Train: 0.232] [Test: 0.383] [Valid: 0.373]\n",
      "#103 [Train: 0.927] [Test: 0.892] [Valid: 0.889]\n",
      "15:53:42.622289\n",
      "#104 [Train: 0.227] [Test: 0.374] [Valid: 0.364]\n",
      "#104 [Train: 0.929] [Test: 0.895] [Valid: 0.890]\n",
      "15:54:13.476463\n",
      "#105 [Train: 0.225] [Test: 0.385] [Valid: 0.374]\n",
      "#105 [Train: 0.929] [Test: 0.890] [Valid: 0.891]\n",
      "15:54:48.229907\n",
      "#106 [Train: 0.222] [Test: 0.376] [Valid: 0.379]\n",
      "#106 [Train: 0.930] [Test: 0.894] [Valid: 0.891]\n",
      "15:55:31.106675\n",
      "#107 [Train: 0.226] [Test: 0.362] [Valid: 0.366]\n",
      "#107 [Train: 0.929] [Test: 0.897] [Valid: 0.893]\n",
      "15:56:01.394006\n",
      "#108 [Train: 0.222] [Test: 0.367] [Valid: 0.375]\n",
      "#108 [Train: 0.931] [Test: 0.895] [Valid: 0.892]\n",
      "15:56:31.103355\n",
      "#109 [Train: 0.220] [Test: 0.381] [Valid: 0.371]\n",
      "#109 [Train: 0.931] [Test: 0.893] [Valid: 0.892]\n",
      "15:57:01.161372\n",
      "#110 [Train: 0.213] [Test: 0.378] [Valid: 0.371]\n",
      "#110 [Train: 0.933] [Test: 0.894] [Valid: 0.892]\n",
      "15:57:31.777985\n",
      "#111 [Train: 0.215] [Test: 0.365] [Valid: 0.356]\n",
      "#111 [Train: 0.933] [Test: 0.898] [Valid: 0.897]\n",
      "15:58:01.642377\n",
      "#112 [Train: 0.213] [Test: 0.375] [Valid: 0.368]\n",
      "#112 [Train: 0.932] [Test: 0.893] [Valid: 0.894]\n",
      "15:58:32.113731\n",
      "#113 [Train: 0.208] [Test: 0.364] [Valid: 0.362]\n",
      "#113 [Train: 0.934] [Test: 0.898] [Valid: 0.893]\n",
      "15:59:11.070184\n",
      "#114 [Train: 0.202] [Test: 0.365] [Valid: 0.347]\n",
      "#114 [Train: 0.936] [Test: 0.896] [Valid: 0.900]\n",
      "15:59:54.893393\n",
      "#115 [Train: 0.199] [Test: 0.358] [Valid: 0.359]\n",
      "#115 [Train: 0.937] [Test: 0.899] [Valid: 0.896]\n",
      "16:00:36.865155\n",
      "#116 [Train: 0.199] [Test: 0.355] [Valid: 0.353]\n",
      "#116 [Train: 0.937] [Test: 0.907] [Valid: 0.900]\n",
      "16:01:19.594853\n",
      "#117 [Train: 0.198] [Test: 0.361] [Valid: 0.364]\n",
      "#117 [Train: 0.937] [Test: 0.901] [Valid: 0.895]\n",
      "16:02:02.606481\n",
      "#118 [Train: 0.195] [Test: 0.371] [Valid: 0.366]\n",
      "#118 [Train: 0.938] [Test: 0.895] [Valid: 0.898]\n",
      "16:02:47.406538\n",
      "#119 [Train: 0.193] [Test: 0.364] [Valid: 0.361]\n",
      "#119 [Train: 0.939] [Test: 0.898] [Valid: 0.893]\n",
      "16:03:31.437864\n",
      "#120 [Train: 0.193] [Test: 0.364] [Valid: 0.357]\n",
      "#120 [Train: 0.940] [Test: 0.898] [Valid: 0.900]\n",
      "16:04:14.685394\n",
      "#121 [Train: 0.189] [Test: 0.368] [Valid: 0.369]\n",
      "#121 [Train: 0.939] [Test: 0.898] [Valid: 0.897]\n",
      "16:04:57.550838\n",
      "#122 [Train: 0.189] [Test: 0.341] [Valid: 0.353]\n",
      "#122 [Train: 0.940] [Test: 0.904] [Valid: 0.897]\n",
      "16:05:41.533639\n",
      "#123 [Train: 0.186] [Test: 0.380] [Valid: 0.356]\n",
      "#123 [Train: 0.941] [Test: 0.897] [Valid: 0.900]\n",
      "16:06:25.664165\n",
      "#124 [Train: 0.185] [Test: 0.354] [Valid: 0.360]\n",
      "#124 [Train: 0.942] [Test: 0.901] [Valid: 0.900]\n",
      "16:07:10.437356\n",
      "#125 [Train: 0.189] [Test: 0.362] [Valid: 0.351]\n",
      "#125 [Train: 0.940] [Test: 0.898] [Valid: 0.897]\n",
      "16:07:55.109838\n",
      "#126 [Train: 0.185] [Test: 0.362] [Valid: 0.351]\n",
      "#126 [Train: 0.941] [Test: 0.901] [Valid: 0.898]\n",
      "16:08:39.442908\n",
      "#127 [Train: 0.178] [Test: 0.351] [Valid: 0.357]\n",
      "#127 [Train: 0.943] [Test: 0.901] [Valid: 0.897]\n",
      "16:09:23.487978\n",
      "#128 [Train: 0.179] [Test: 0.349] [Valid: 0.342]\n",
      "#128 [Train: 0.943] [Test: 0.903] [Valid: 0.904]\n",
      "16:10:05.898617\n",
      "#129 [Train: 0.174] [Test: 0.364] [Valid: 0.357]\n",
      "#129 [Train: 0.945] [Test: 0.900] [Valid: 0.896]\n",
      "16:10:48.977796\n",
      "#130 [Train: 0.174] [Test: 0.354] [Valid: 0.364]\n",
      "#130 [Train: 0.945] [Test: 0.905] [Valid: 0.898]\n",
      "16:11:31.853780\n",
      "#131 [Train: 0.177] [Test: 0.354] [Valid: 0.359]\n",
      "#131 [Train: 0.944] [Test: 0.901] [Valid: 0.897]\n",
      "16:12:13.792686\n",
      "#132 [Train: 0.172] [Test: 0.346] [Valid: 0.371]\n",
      "#132 [Train: 0.946] [Test: 0.903] [Valid: 0.897]\n",
      "16:12:57.196934\n",
      "#133 [Train: 0.172] [Test: 0.340] [Valid: 0.353]\n",
      "#133 [Train: 0.945] [Test: 0.905] [Valid: 0.898]\n",
      "16:13:39.305733\n",
      "#134 [Train: 0.170] [Test: 0.356] [Valid: 0.354]\n",
      "#134 [Train: 0.946] [Test: 0.903] [Valid: 0.899]\n",
      "16:14:22.225871\n",
      "#135 [Train: 0.168] [Test: 0.359] [Valid: 0.349]\n",
      "#135 [Train: 0.946] [Test: 0.904] [Valid: 0.901]\n",
      "16:15:05.452987\n",
      "#136 [Train: 0.168] [Test: 0.348] [Valid: 0.346]\n",
      "#136 [Train: 0.946] [Test: 0.902] [Valid: 0.903]\n",
      "16:15:48.620487\n",
      "#137 [Train: 0.165] [Test: 0.341] [Valid: 0.350]\n",
      "#137 [Train: 0.948] [Test: 0.907] [Valid: 0.904]\n",
      "16:16:30.590686\n",
      "#138 [Train: 0.164] [Test: 0.367] [Valid: 0.364]\n",
      "#138 [Train: 0.948] [Test: 0.902] [Valid: 0.900]\n",
      "16:17:13.521916\n",
      "#139 [Train: 0.160] [Test: 0.353] [Valid: 0.350]\n",
      "#139 [Train: 0.949] [Test: 0.903] [Valid: 0.903]\n",
      "16:17:55.752836\n",
      "#140 [Train: 0.161] [Test: 0.347] [Valid: 0.346]\n",
      "#140 [Train: 0.948] [Test: 0.905] [Valid: 0.906]\n",
      "16:18:39.057255\n",
      "#141 [Train: 0.158] [Test: 0.338] [Valid: 0.349]\n",
      "#141 [Train: 0.950] [Test: 0.908] [Valid: 0.904]\n",
      "16:19:22.803342\n",
      "#142 [Train: 0.159] [Test: 0.362] [Valid: 0.344]\n",
      "#142 [Train: 0.950] [Test: 0.904] [Valid: 0.901]\n",
      "16:20:04.821685\n",
      "#143 [Train: 0.155] [Test: 0.345] [Valid: 0.339]\n",
      "#143 [Train: 0.951] [Test: 0.908] [Valid: 0.904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:20:48.066235\n",
      "#144 [Train: 0.154] [Test: 0.350] [Valid: 0.353]\n",
      "#144 [Train: 0.951] [Test: 0.908] [Valid: 0.906]\n",
      "16:21:30.902570\n",
      "#145 [Train: 0.154] [Test: 0.353] [Valid: 0.353]\n",
      "#145 [Train: 0.951] [Test: 0.906] [Valid: 0.905]\n",
      "16:22:14.158081\n",
      "#146 [Train: 0.152] [Test: 0.360] [Valid: 0.353]\n",
      "#146 [Train: 0.951] [Test: 0.904] [Valid: 0.900]\n",
      "16:22:56.918339\n",
      "#147 [Train: 0.154] [Test: 0.355] [Valid: 0.344]\n",
      "#147 [Train: 0.951] [Test: 0.906] [Valid: 0.903]\n",
      "16:23:40.008529\n",
      "#148 [Train: 0.151] [Test: 0.367] [Valid: 0.348]\n",
      "#148 [Train: 0.952] [Test: 0.901] [Valid: 0.907]\n",
      "16:24:23.534214\n",
      "#149 [Train: 0.147] [Test: 0.350] [Valid: 0.364]\n",
      "#149 [Train: 0.953] [Test: 0.907] [Valid: 0.903]\n",
      "16:25:05.643860\n",
      "#150 [Train: 0.152] [Test: 0.351] [Valid: 0.359]\n",
      "#150 [Train: 0.952] [Test: 0.905] [Valid: 0.901]\n",
      "16:25:48.548885\n",
      "#151 [Train: 0.147] [Test: 0.366] [Valid: 0.352]\n",
      "#151 [Train: 0.954] [Test: 0.903] [Valid: 0.902]\n",
      "16:26:30.688074\n",
      "#152 [Train: 0.145] [Test: 0.346] [Valid: 0.347]\n",
      "#152 [Train: 0.953] [Test: 0.907] [Valid: 0.902]\n",
      "16:27:13.105644\n",
      "#153 [Train: 0.143] [Test: 0.342] [Valid: 0.343]\n",
      "#153 [Train: 0.954] [Test: 0.907] [Valid: 0.909]\n",
      "16:27:42.713311\n",
      "#154 [Train: 0.141] [Test: 0.372] [Valid: 0.360]\n",
      "#154 [Train: 0.955] [Test: 0.899] [Valid: 0.899]\n",
      "16:28:18.384692\n",
      "#155 [Train: 0.143] [Test: 0.327] [Valid: 0.349]\n",
      "#155 [Train: 0.954] [Test: 0.911] [Valid: 0.906]\n",
      "16:29:00.224635\n",
      "#156 [Train: 0.139] [Test: 0.344] [Valid: 0.336]\n",
      "#156 [Train: 0.956] [Test: 0.908] [Valid: 0.906]\n",
      "16:29:41.245796\n",
      "#157 [Train: 0.137] [Test: 0.366] [Valid: 0.358]\n",
      "#157 [Train: 0.956] [Test: 0.905] [Valid: 0.907]\n",
      "16:30:24.457167\n",
      "#158 [Train: 0.140] [Test: 0.351] [Valid: 0.352]\n",
      "#158 [Train: 0.956] [Test: 0.907] [Valid: 0.909]\n",
      "16:31:05.232533\n",
      "#159 [Train: 0.135] [Test: 0.353] [Valid: 0.350]\n",
      "#159 [Train: 0.957] [Test: 0.908] [Valid: 0.907]\n",
      "16:31:47.530479\n",
      "#160 [Train: 0.132] [Test: 0.351] [Valid: 0.346]\n",
      "#160 [Train: 0.958] [Test: 0.907] [Valid: 0.906]\n",
      "16:32:30.087328\n",
      "#161 [Train: 0.134] [Test: 0.347] [Valid: 0.359]\n",
      "#161 [Train: 0.957] [Test: 0.910] [Valid: 0.907]\n",
      "16:33:12.401772\n",
      "#162 [Train: 0.136] [Test: 0.353] [Valid: 0.343]\n",
      "#162 [Train: 0.956] [Test: 0.906] [Valid: 0.908]\n",
      "16:33:52.718481\n",
      "#163 [Train: 0.132] [Test: 0.357] [Valid: 0.357]\n",
      "#163 [Train: 0.957] [Test: 0.906] [Valid: 0.902]\n",
      "16:34:35.780444\n",
      "#164 [Train: 0.130] [Test: 0.354] [Valid: 0.355]\n",
      "#164 [Train: 0.959] [Test: 0.911] [Valid: 0.908]\n",
      "16:35:17.981831\n",
      "#165 [Train: 0.131] [Test: 0.355] [Valid: 0.346]\n",
      "#165 [Train: 0.958] [Test: 0.907] [Valid: 0.908]\n",
      "16:36:00.861008\n",
      "#166 [Train: 0.129] [Test: 0.349] [Valid: 0.351]\n",
      "#166 [Train: 0.959] [Test: 0.907] [Valid: 0.906]\n",
      "16:36:42.702178\n",
      "#167 [Train: 0.130] [Test: 0.362] [Valid: 0.373]\n",
      "#167 [Train: 0.959] [Test: 0.909] [Valid: 0.902]\n",
      "16:37:25.602021\n",
      "#168 [Train: 0.131] [Test: 0.340] [Valid: 0.350]\n",
      "#168 [Train: 0.958] [Test: 0.911] [Valid: 0.908]\n",
      "16:38:08.945313\n",
      "#169 [Train: 0.127] [Test: 0.341] [Valid: 0.354]\n",
      "#169 [Train: 0.959] [Test: 0.911] [Valid: 0.906]\n",
      "16:38:50.351915\n",
      "#170 [Train: 0.126] [Test: 0.352] [Valid: 0.355]\n",
      "#170 [Train: 0.959] [Test: 0.910] [Valid: 0.907]\n",
      "16:39:32.873272\n",
      "#171 [Train: 0.123] [Test: 0.364] [Valid: 0.368]\n",
      "#171 [Train: 0.961] [Test: 0.905] [Valid: 0.904]\n",
      "16:40:15.453679\n",
      "#172 [Train: 0.126] [Test: 0.355] [Valid: 0.354]\n",
      "#172 [Train: 0.960] [Test: 0.911] [Valid: 0.908]\n",
      "16:40:59.124916\n",
      "#173 [Train: 0.121] [Test: 0.346] [Valid: 0.357]\n",
      "#173 [Train: 0.961] [Test: 0.912] [Valid: 0.905]\n",
      "16:41:42.103289\n",
      "#174 [Train: 0.119] [Test: 0.360] [Valid: 0.356]\n",
      "#174 [Train: 0.963] [Test: 0.908] [Valid: 0.907]\n",
      "16:42:23.860341\n",
      "#175 [Train: 0.120] [Test: 0.360] [Valid: 0.369]\n",
      "#175 [Train: 0.961] [Test: 0.910] [Valid: 0.903]\n",
      "16:42:57.209989\n",
      "#176 [Train: 0.118] [Test: 0.353] [Valid: 0.365]\n",
      "#176 [Train: 0.962] [Test: 0.911] [Valid: 0.902]\n",
      "16:43:27.012127\n",
      "#177 [Train: 0.120] [Test: 0.356] [Valid: 0.353]\n",
      "#177 [Train: 0.961] [Test: 0.911] [Valid: 0.908]\n",
      "16:43:55.933764\n",
      "#178 [Train: 0.116] [Test: 0.331] [Valid: 0.332]\n",
      "#178 [Train: 0.963] [Test: 0.918] [Valid: 0.911]\n",
      "16:44:24.888322\n",
      "#179 [Train: 0.117] [Test: 0.346] [Valid: 0.337]\n",
      "#179 [Train: 0.962] [Test: 0.914] [Valid: 0.912]\n",
      "16:44:53.741529\n",
      "#180 [Train: 0.114] [Test: 0.350] [Valid: 0.368]\n",
      "#180 [Train: 0.962] [Test: 0.912] [Valid: 0.905]\n",
      "16:45:22.774575\n",
      "#181 [Train: 0.115] [Test: 0.347] [Valid: 0.350]\n",
      "#181 [Train: 0.963] [Test: 0.909] [Valid: 0.909]\n",
      "16:45:52.078652\n",
      "#182 [Train: 0.116] [Test: 0.367] [Valid: 0.351]\n",
      "#182 [Train: 0.963] [Test: 0.909] [Valid: 0.907]\n",
      "16:46:21.285084\n",
      "#183 [Train: 0.114] [Test: 0.339] [Valid: 0.347]\n",
      "#183 [Train: 0.963] [Test: 0.912] [Valid: 0.907]\n",
      "16:46:50.738951\n",
      "#184 [Train: 0.109] [Test: 0.353] [Valid: 0.367]\n",
      "#184 [Train: 0.966] [Test: 0.910] [Valid: 0.906]\n",
      "16:47:20.144991\n",
      "#185 [Train: 0.112] [Test: 0.340] [Valid: 0.346]\n",
      "#185 [Train: 0.964] [Test: 0.915] [Valid: 0.909]\n",
      "16:47:50.170225\n",
      "#186 [Train: 0.108] [Test: 0.353] [Valid: 0.368]\n",
      "#186 [Train: 0.965] [Test: 0.914] [Valid: 0.907]\n",
      "16:48:18.972781\n",
      "#187 [Train: 0.108] [Test: 0.359] [Valid: 0.358]\n",
      "#187 [Train: 0.965] [Test: 0.913] [Valid: 0.905]\n",
      "16:48:48.684842\n",
      "#188 [Train: 0.109] [Test: 0.334] [Valid: 0.345]\n",
      "#188 [Train: 0.965] [Test: 0.913] [Valid: 0.908]\n",
      "16:49:18.807512\n",
      "#189 [Train: 0.108] [Test: 0.360] [Valid: 0.354]\n",
      "#189 [Train: 0.965] [Test: 0.913] [Valid: 0.909]\n",
      "16:49:48.093460\n",
      "#190 [Train: 0.110] [Test: 0.369] [Valid: 0.358]\n",
      "#190 [Train: 0.964] [Test: 0.910] [Valid: 0.909]\n",
      "16:50:17.103642\n",
      "#191 [Train: 0.107] [Test: 0.375] [Valid: 0.376]\n",
      "#191 [Train: 0.966] [Test: 0.911] [Valid: 0.906]\n",
      "16:50:46.780687\n",
      "#192 [Train: 0.107] [Test: 0.386] [Valid: 0.366]\n",
      "#192 [Train: 0.966] [Test: 0.902] [Valid: 0.905]\n",
      "16:51:16.166170\n",
      "#193 [Train: 0.106] [Test: 0.349] [Valid: 0.369]\n",
      "#193 [Train: 0.966] [Test: 0.914] [Valid: 0.907]\n",
      "16:51:45.478112\n",
      "#194 [Train: 0.105] [Test: 0.358] [Valid: 0.369]\n",
      "#194 [Train: 0.966] [Test: 0.914] [Valid: 0.908]\n",
      "16:52:13.462767\n",
      "#195 [Train: 0.102] [Test: 0.359] [Valid: 0.367]\n",
      "#195 [Train: 0.968] [Test: 0.912] [Valid: 0.910]\n",
      "16:52:42.464487\n",
      "#196 [Train: 0.103] [Test: 0.358] [Valid: 0.365]\n",
      "#196 [Train: 0.967] [Test: 0.911] [Valid: 0.911]\n",
      "16:53:11.894500\n",
      "#197 [Train: 0.101] [Test: 0.362] [Valid: 0.370]\n",
      "#197 [Train: 0.969] [Test: 0.911] [Valid: 0.907]\n",
      "16:53:41.528388\n",
      "#198 [Train: 0.101] [Test: 0.366] [Valid: 0.360]\n",
      "#198 [Train: 0.968] [Test: 0.915] [Valid: 0.910]\n",
      "16:54:10.891987\n",
      "#199 [Train: 0.099] [Test: 0.359] [Valid: 0.370]\n",
      "#199 [Train: 0.968] [Test: 0.914] [Valid: 0.910]\n",
      "16:54:40.285595\n",
      "#200 [Train: 0.100] [Test: 0.364] [Valid: 0.370]\n",
      "#200 [Train: 0.967] [Test: 0.915] [Valid: 0.911]\n",
      "16:55:09.373086\n",
      "#201 [Train: 0.097] [Test: 0.355] [Valid: 0.353]\n",
      "#201 [Train: 0.969] [Test: 0.915] [Valid: 0.910]\n",
      "16:55:38.349435\n",
      "#202 [Train: 0.097] [Test: 0.363] [Valid: 0.360]\n",
      "#202 [Train: 0.969] [Test: 0.912] [Valid: 0.910]\n",
      "16:56:07.463881\n",
      "#203 [Train: 0.097] [Test: 0.363] [Valid: 0.362]\n",
      "#203 [Train: 0.969] [Test: 0.912] [Valid: 0.910]\n",
      "16:56:36.836415\n",
      "#204 [Train: 0.095] [Test: 0.355] [Valid: 0.357]\n",
      "#204 [Train: 0.969] [Test: 0.911] [Valid: 0.911]\n",
      "16:57:05.290462\n",
      "#205 [Train: 0.095] [Test: 0.369] [Valid: 0.366]\n",
      "#205 [Train: 0.970] [Test: 0.912] [Valid: 0.908]\n",
      "16:57:34.623431\n",
      "#206 [Train: 0.095] [Test: 0.356] [Valid: 0.356]\n",
      "#206 [Train: 0.970] [Test: 0.918] [Valid: 0.912]\n",
      "16:58:03.351827\n",
      "#207 [Train: 0.094] [Test: 0.359] [Valid: 0.358]\n",
      "#207 [Train: 0.970] [Test: 0.913] [Valid: 0.909]\n",
      "16:58:32.785408\n",
      "#208 [Train: 0.094] [Test: 0.380] [Valid: 0.361]\n",
      "#208 [Train: 0.970] [Test: 0.914] [Valid: 0.911]\n",
      "16:59:01.946655\n",
      "#209 [Train: 0.095] [Test: 0.364] [Valid: 0.367]\n",
      "#209 [Train: 0.970] [Test: 0.914] [Valid: 0.909]\n",
      "16:59:31.700329\n",
      "#210 [Train: 0.094] [Test: 0.370] [Valid: 0.360]\n",
      "#210 [Train: 0.970] [Test: 0.915] [Valid: 0.911]\n",
      "17:00:00.747375\n",
      "#211 [Train: 0.093] [Test: 0.364] [Valid: 0.358]\n",
      "#211 [Train: 0.970] [Test: 0.915] [Valid: 0.913]\n",
      "17:00:28.881489\n",
      "#212 [Train: 0.092] [Test: 0.386] [Valid: 0.376]\n",
      "#212 [Train: 0.971] [Test: 0.912] [Valid: 0.908]\n",
      "17:00:58.469699\n",
      "#213 [Train: 0.093] [Test: 0.360] [Valid: 0.364]\n",
      "#213 [Train: 0.970] [Test: 0.912] [Valid: 0.909]\n",
      "17:01:27.628281\n",
      "#214 [Train: 0.091] [Test: 0.373] [Valid: 0.372]\n",
      "#214 [Train: 0.972] [Test: 0.913] [Valid: 0.909]\n",
      "17:01:56.961910\n",
      "#215 [Train: 0.091] [Test: 0.372] [Valid: 0.376]\n",
      "#215 [Train: 0.971] [Test: 0.912] [Valid: 0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:02:25.091242\n",
      "#216 [Train: 0.093] [Test: 0.358] [Valid: 0.359]\n",
      "#216 [Train: 0.970] [Test: 0.916] [Valid: 0.914]\n",
      "17:02:54.950550\n",
      "#217 [Train: 0.090] [Test: 0.365] [Valid: 0.395]\n",
      "#217 [Train: 0.971] [Test: 0.915] [Valid: 0.906]\n",
      "17:03:24.441834\n",
      "#218 [Train: 0.090] [Test: 0.356] [Valid: 0.371]\n",
      "#218 [Train: 0.971] [Test: 0.916] [Valid: 0.909]\n",
      "17:03:53.463063\n",
      "#219 [Train: 0.086] [Test: 0.350] [Valid: 0.358]\n",
      "#219 [Train: 0.972] [Test: 0.915] [Valid: 0.910]\n",
      "17:04:22.478779\n",
      "#220 [Train: 0.086] [Test: 0.354] [Valid: 0.369]\n",
      "#220 [Train: 0.973] [Test: 0.919] [Valid: 0.912]\n",
      "17:04:51.534501\n",
      "#221 [Train: 0.086] [Test: 0.370] [Valid: 0.375]\n",
      "#221 [Train: 0.973] [Test: 0.916] [Valid: 0.911]\n",
      "17:05:20.239788\n",
      "#222 [Train: 0.087] [Test: 0.357] [Valid: 0.376]\n",
      "#222 [Train: 0.972] [Test: 0.918] [Valid: 0.910]\n",
      "17:05:49.799523\n",
      "#223 [Train: 0.083] [Test: 0.377] [Valid: 0.364]\n",
      "#223 [Train: 0.973] [Test: 0.914] [Valid: 0.912]\n",
      "17:06:18.455636\n",
      "#224 [Train: 0.083] [Test: 0.390] [Valid: 0.382]\n",
      "#224 [Train: 0.974] [Test: 0.911] [Valid: 0.910]\n",
      "17:06:47.781169\n",
      "#225 [Train: 0.084] [Test: 0.369] [Valid: 0.366]\n",
      "#225 [Train: 0.973] [Test: 0.915] [Valid: 0.910]\n",
      "17:07:16.862483\n",
      "#226 [Train: 0.085] [Test: 0.386] [Valid: 0.388]\n",
      "#226 [Train: 0.973] [Test: 0.913] [Valid: 0.908]\n",
      "17:07:45.555660\n",
      "#227 [Train: 0.083] [Test: 0.372] [Valid: 0.382]\n",
      "#227 [Train: 0.974] [Test: 0.914] [Valid: 0.908]\n",
      "17:08:14.324460\n",
      "#228 [Train: 0.081] [Test: 0.379] [Valid: 0.369]\n",
      "#228 [Train: 0.974] [Test: 0.913] [Valid: 0.910]\n",
      "17:08:43.275537\n",
      "#229 [Train: 0.083] [Test: 0.378] [Valid: 0.383]\n",
      "#229 [Train: 0.974] [Test: 0.914] [Valid: 0.912]\n",
      "17:09:12.831007\n",
      "#230 [Train: 0.081] [Test: 0.362] [Valid: 0.374]\n",
      "#230 [Train: 0.974] [Test: 0.918] [Valid: 0.912]\n",
      "17:09:42.093735\n",
      "#231 [Train: 0.079] [Test: 0.387] [Valid: 0.394]\n",
      "#231 [Train: 0.975] [Test: 0.911] [Valid: 0.907]\n",
      "17:10:11.398119\n",
      "#232 [Train: 0.078] [Test: 0.364] [Valid: 0.378]\n",
      "#232 [Train: 0.976] [Test: 0.919] [Valid: 0.914]\n",
      "17:10:40.414795\n",
      "#233 [Train: 0.081] [Test: 0.374] [Valid: 0.375]\n",
      "#233 [Train: 0.974] [Test: 0.917] [Valid: 0.911]\n",
      "17:11:08.890248\n",
      "#234 [Train: 0.079] [Test: 0.376] [Valid: 0.385]\n",
      "#234 [Train: 0.975] [Test: 0.917] [Valid: 0.910]\n",
      "17:11:38.156964\n",
      "#235 [Train: 0.076] [Test: 0.377] [Valid: 0.376]\n",
      "#235 [Train: 0.976] [Test: 0.918] [Valid: 0.914]\n",
      "17:12:07.196276\n",
      "#236 [Train: 0.075] [Test: 0.380] [Valid: 0.382]\n",
      "#236 [Train: 0.977] [Test: 0.914] [Valid: 0.915]\n",
      "17:12:36.093555\n",
      "#237 [Train: 0.077] [Test: 0.377] [Valid: 0.389]\n",
      "#237 [Train: 0.975] [Test: 0.914] [Valid: 0.908]\n",
      "17:13:04.985261\n",
      "#238 [Train: 0.075] [Test: 0.363] [Valid: 0.389]\n",
      "#238 [Train: 0.976] [Test: 0.917] [Valid: 0.909]\n",
      "17:13:33.935568\n",
      "#239 [Train: 0.076] [Test: 0.362] [Valid: 0.371]\n",
      "#239 [Train: 0.976] [Test: 0.916] [Valid: 0.912]\n",
      "17:14:02.794874\n",
      "#240 [Train: 0.074] [Test: 0.390] [Valid: 0.412]\n",
      "#240 [Train: 0.976] [Test: 0.917] [Valid: 0.910]\n",
      "17:14:32.045146\n",
      "#241 [Train: 0.075] [Test: 0.363] [Valid: 0.376]\n",
      "#241 [Train: 0.976] [Test: 0.921] [Valid: 0.912]\n",
      "17:15:01.060352\n",
      "#242 [Train: 0.075] [Test: 0.403] [Valid: 0.420]\n",
      "#242 [Train: 0.976] [Test: 0.914] [Valid: 0.907]\n",
      "17:15:30.730602\n",
      "#243 [Train: 0.075] [Test: 0.375] [Valid: 0.402]\n",
      "#243 [Train: 0.976] [Test: 0.917] [Valid: 0.910]\n",
      "17:15:59.655400\n",
      "#244 [Train: 0.072] [Test: 0.360] [Valid: 0.377]\n",
      "#244 [Train: 0.978] [Test: 0.921] [Valid: 0.910]\n",
      "17:16:28.555877\n",
      "#245 [Train: 0.072] [Test: 0.379] [Valid: 0.377]\n",
      "#245 [Train: 0.977] [Test: 0.917] [Valid: 0.910]\n",
      "17:16:57.467795\n",
      "#246 [Train: 0.073] [Test: 0.367] [Valid: 0.379]\n",
      "#246 [Train: 0.976] [Test: 0.917] [Valid: 0.910]\n",
      "17:17:27.175317\n",
      "#247 [Train: 0.073] [Test: 0.368] [Valid: 0.382]\n",
      "#247 [Train: 0.977] [Test: 0.918] [Valid: 0.914]\n",
      "17:17:56.621953\n",
      "#248 [Train: 0.071] [Test: 0.403] [Valid: 0.395]\n",
      "#248 [Train: 0.977] [Test: 0.911] [Valid: 0.912]\n",
      "17:18:25.028450\n",
      "#249 [Train: 0.072] [Test: 0.386] [Valid: 0.392]\n",
      "#249 [Train: 0.978] [Test: 0.919] [Valid: 0.911]\n",
      "17:18:53.653586\n",
      "#250 [Train: 0.072] [Test: 0.390] [Valid: 0.400]\n",
      "#250 [Train: 0.977] [Test: 0.920] [Valid: 0.911]\n",
      "17:19:22.449856\n",
      "#251 [Train: 0.070] [Test: 0.406] [Valid: 0.380]\n",
      "#251 [Train: 0.978] [Test: 0.913] [Valid: 0.915]\n",
      "17:19:50.469122\n",
      "#252 [Train: 0.071] [Test: 0.377] [Valid: 0.379]\n",
      "#252 [Train: 0.978] [Test: 0.918] [Valid: 0.914]\n",
      "17:20:20.015980\n",
      "#253 [Train: 0.069] [Test: 0.387] [Valid: 0.384]\n",
      "#253 [Train: 0.978] [Test: 0.916] [Valid: 0.914]\n",
      "17:20:48.860755\n",
      "#254 [Train: 0.070] [Test: 0.410] [Valid: 0.404]\n",
      "#254 [Train: 0.977] [Test: 0.914] [Valid: 0.907]\n",
      "17:21:17.897340\n",
      "#255 [Train: 0.068] [Test: 0.387] [Valid: 0.397]\n",
      "#255 [Train: 0.979] [Test: 0.916] [Valid: 0.915]\n",
      "17:21:46.917331\n",
      "#256 [Train: 0.067] [Test: 0.382] [Valid: 0.397]\n",
      "#256 [Train: 0.979] [Test: 0.916] [Valid: 0.912]\n",
      "17:22:16.602793\n",
      "#257 [Train: 0.067] [Test: 0.395] [Valid: 0.393]\n",
      "#257 [Train: 0.979] [Test: 0.916] [Valid: 0.911]\n",
      "17:22:45.817605\n",
      "#258 [Train: 0.065] [Test: 0.395] [Valid: 0.397]\n",
      "#258 [Train: 0.979] [Test: 0.919] [Valid: 0.911]\n",
      "17:23:15.108287\n",
      "#259 [Train: 0.069] [Test: 0.381] [Valid: 0.395]\n",
      "#259 [Train: 0.978] [Test: 0.921] [Valid: 0.913]\n",
      "17:23:44.665210\n",
      "#260 [Train: 0.068] [Test: 0.378] [Valid: 0.388]\n",
      "#260 [Train: 0.979] [Test: 0.921] [Valid: 0.915]\n",
      "17:24:13.688759\n",
      "#261 [Train: 0.068] [Test: 0.391] [Valid: 0.407]\n",
      "#261 [Train: 0.978] [Test: 0.918] [Valid: 0.910]\n",
      "17:24:43.174620\n",
      "#262 [Train: 0.066] [Test: 0.393] [Valid: 0.398]\n",
      "#262 [Train: 0.980] [Test: 0.919] [Valid: 0.909]\n",
      "17:25:13.045587\n",
      "#263 [Train: 0.069] [Test: 0.389] [Valid: 0.395]\n",
      "#263 [Train: 0.978] [Test: 0.916] [Valid: 0.911]\n",
      "17:25:42.158053\n",
      "#264 [Train: 0.067] [Test: 0.370] [Valid: 0.388]\n",
      "#264 [Train: 0.979] [Test: 0.922] [Valid: 0.914]\n",
      "17:26:10.335546\n",
      "#265 [Train: 0.066] [Test: 0.392] [Valid: 0.390]\n",
      "#265 [Train: 0.979] [Test: 0.917] [Valid: 0.912]\n",
      "17:26:39.689082\n",
      "#266 [Train: 0.067] [Test: 0.395] [Valid: 0.387]\n",
      "#266 [Train: 0.979] [Test: 0.918] [Valid: 0.914]\n",
      "17:27:09.184294\n",
      "#267 [Train: 0.060] [Test: 0.391] [Valid: 0.420]\n",
      "#267 [Train: 0.981] [Test: 0.918] [Valid: 0.909]\n",
      "17:27:38.171188\n",
      "#268 [Train: 0.066] [Test: 0.394] [Valid: 0.396]\n",
      "#268 [Train: 0.979] [Test: 0.914] [Valid: 0.914]\n",
      "17:28:07.113941\n",
      "#269 [Train: 0.064] [Test: 0.394] [Valid: 0.402]\n",
      "#269 [Train: 0.980] [Test: 0.919] [Valid: 0.917]\n",
      "17:28:35.109720\n",
      "#270 [Train: 0.063] [Test: 0.393] [Valid: 0.396]\n",
      "#270 [Train: 0.980] [Test: 0.920] [Valid: 0.913]\n",
      "17:29:03.470000\n",
      "#271 [Train: 0.059] [Test: 0.396] [Valid: 0.391]\n",
      "#271 [Train: 0.981] [Test: 0.918] [Valid: 0.915]\n",
      "17:29:32.548547\n",
      "#272 [Train: 0.061] [Test: 0.393] [Valid: 0.414]\n",
      "#272 [Train: 0.981] [Test: 0.920] [Valid: 0.911]\n",
      "17:30:01.357465\n",
      "#273 [Train: 0.063] [Test: 0.420] [Valid: 0.380]\n",
      "#273 [Train: 0.980] [Test: 0.911] [Valid: 0.918]\n",
      "17:30:30.734788\n",
      "#274 [Train: 0.061] [Test: 0.379] [Valid: 0.396]\n",
      "#274 [Train: 0.980] [Test: 0.922] [Valid: 0.913]\n",
      "17:31:00.442400\n",
      "#275 [Train: 0.062] [Test: 0.417] [Valid: 0.423]\n",
      "#275 [Train: 0.981] [Test: 0.917] [Valid: 0.907]\n",
      "17:31:31.488060\n",
      "#276 [Train: 0.062] [Test: 0.400] [Valid: 0.422]\n",
      "#276 [Train: 0.980] [Test: 0.920] [Valid: 0.912]\n",
      "17:32:03.753984\n",
      "#277 [Train: 0.060] [Test: 0.395] [Valid: 0.402]\n",
      "#277 [Train: 0.981] [Test: 0.920] [Valid: 0.913]\n",
      "17:32:34.596289\n",
      "#278 [Train: 0.057] [Test: 0.411] [Valid: 0.418]\n",
      "#278 [Train: 0.982] [Test: 0.918] [Valid: 0.912]\n",
      "17:33:05.831789\n",
      "#279 [Train: 0.060] [Test: 0.407] [Valid: 0.408]\n",
      "#279 [Train: 0.981] [Test: 0.916] [Valid: 0.911]\n",
      "17:33:37.452970\n",
      "#280 [Train: 0.062] [Test: 0.376] [Valid: 0.382]\n",
      "#280 [Train: 0.980] [Test: 0.920] [Valid: 0.916]\n",
      "17:34:09.093851\n",
      "#281 [Train: 0.057] [Test: 0.388] [Valid: 0.394]\n",
      "#281 [Train: 0.982] [Test: 0.919] [Valid: 0.912]\n",
      "17:34:40.703962\n",
      "#282 [Train: 0.060] [Test: 0.405] [Valid: 0.415]\n",
      "#282 [Train: 0.981] [Test: 0.922] [Valid: 0.913]\n",
      "17:35:12.227584\n",
      "#283 [Train: 0.058] [Test: 0.372] [Valid: 0.412]\n",
      "#283 [Train: 0.982] [Test: 0.920] [Valid: 0.914]\n",
      "17:35:43.271543\n",
      "#284 [Train: 0.058] [Test: 0.396] [Valid: 0.411]\n",
      "#284 [Train: 0.982] [Test: 0.916] [Valid: 0.913]\n",
      "17:36:14.506469\n",
      "#285 [Train: 0.060] [Test: 0.392] [Valid: 0.408]\n",
      "#285 [Train: 0.981] [Test: 0.922] [Valid: 0.912]\n",
      "17:36:45.587523\n",
      "#286 [Train: 0.058] [Test: 0.382] [Valid: 0.399]\n",
      "#286 [Train: 0.982] [Test: 0.920] [Valid: 0.914]\n",
      "17:37:16.570845\n",
      "#287 [Train: 0.058] [Test: 0.412] [Valid: 0.440]\n",
      "#287 [Train: 0.982] [Test: 0.919] [Valid: 0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:37:48.228743\n",
      "#288 [Train: 0.056] [Test: 0.402] [Valid: 0.412]\n",
      "#288 [Train: 0.982] [Test: 0.921] [Valid: 0.912]\n",
      "17:38:19.618501\n",
      "#289 [Train: 0.061] [Test: 0.405] [Valid: 0.414]\n",
      "#289 [Train: 0.980] [Test: 0.921] [Valid: 0.914]\n",
      "17:38:50.835841\n",
      "#290 [Train: 0.058] [Test: 0.408] [Valid: 0.401]\n",
      "#290 [Train: 0.982] [Test: 0.917] [Valid: 0.916]\n",
      "17:39:22.043195\n",
      "#291 [Train: 0.056] [Test: 0.396] [Valid: 0.414]\n",
      "#291 [Train: 0.982] [Test: 0.916] [Valid: 0.915]\n",
      "17:39:52.514822\n",
      "#292 [Train: 0.056] [Test: 0.386] [Valid: 0.426]\n",
      "#292 [Train: 0.982] [Test: 0.919] [Valid: 0.913]\n",
      "17:40:21.871094\n",
      "#293 [Train: 0.059] [Test: 0.424] [Valid: 0.419]\n",
      "#293 [Train: 0.981] [Test: 0.914] [Valid: 0.910]\n",
      "17:40:50.642737\n",
      "#294 [Train: 0.056] [Test: 0.411] [Valid: 0.418]\n",
      "#294 [Train: 0.982] [Test: 0.915] [Valid: 0.913]\n",
      "17:41:19.457436\n",
      "#295 [Train: 0.057] [Test: 0.431] [Valid: 0.431]\n",
      "#295 [Train: 0.982] [Test: 0.914] [Valid: 0.908]\n",
      "17:41:47.657032\n",
      "#296 [Train: 0.055] [Test: 0.397] [Valid: 0.408]\n",
      "#296 [Train: 0.983] [Test: 0.921] [Valid: 0.915]\n",
      "17:42:17.158272\n",
      "#297 [Train: 0.054] [Test: 0.420] [Valid: 0.411]\n",
      "#297 [Train: 0.983] [Test: 0.916] [Valid: 0.912]\n",
      "17:42:47.760082\n",
      "#298 [Train: 0.055] [Test: 0.420] [Valid: 0.411]\n",
      "#298 [Train: 0.983] [Test: 0.916] [Valid: 0.917]\n",
      "17:43:18.803305\n",
      "#299 [Train: 0.053] [Test: 0.405] [Valid: 0.397]\n",
      "#299 [Train: 0.984] [Test: 0.920] [Valid: 0.917]\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCH = 300\n",
    "\n",
    "writer = SummaryWriter(log_dir=run_name)\n",
    "\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    training_loss_list = list()\n",
    "    batch_generator = dataset_loader_training.batch_generator()\n",
    "    model.train()\n",
    "    \n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "\n",
    "    for (batch, label) in batch_generator:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(torch.cuda.FloatTensor(batch))\n",
    "        loss = F.nll_loss(pred, torch.cuda.LongTensor(label))\n",
    "        loss.backward()\n",
    "        training_loss_list.append(loss.item())\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, pred_label = torch.max(pred, 1)\n",
    "        correct_num += int((pred_label == torch.cuda.LongTensor(label)).sum().cpu().numpy())\n",
    "        total_num += len(label)\n",
    "        \n",
    "    acc_train = correct_num / total_num\n",
    "\n",
    "    testing_loss_list = list()\n",
    "\n",
    "    batch_generator = dataset_loader_testing.batch_generator()\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "\n",
    "    for (batch, label) in batch_generator:\n",
    "    #     optimizer.zero_grad()\n",
    "        pred = model(torch.cuda.FloatTensor(batch))\n",
    "        loss = F.nll_loss(pred, torch.cuda.LongTensor(label).to(device))\n",
    "#         loss.backward()\n",
    "        testing_loss_list.append(loss.item())\n",
    "    #     optimizer.step()\n",
    "    \n",
    "        _, pred_label = torch.max(pred, 1)\n",
    "        correct_num += int((pred_label == torch.cuda.LongTensor(label)).sum().cpu().numpy())\n",
    "        total_num += len(label)\n",
    "        \n",
    "    acc_test = correct_num / total_num\n",
    "\n",
    "    validation_loss_list = list()\n",
    "\n",
    "    batch_generator = dataset_loader_validation.batch_generator()\n",
    "    \n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "\n",
    "    for (batch, label) in batch_generator:\n",
    "    #     optimizer.zero_grad()\n",
    "        pred = model(torch.cuda.FloatTensor(batch))\n",
    "        loss = F.nll_loss(pred, torch.cuda.LongTensor(label))\n",
    "#         loss.backward()\n",
    "        validation_loss_list.append(loss.item())\n",
    "    #     optimizer.step()\n",
    "    \n",
    "        _, pred_label = torch.max(pred, 1)\n",
    "        correct_num += int((pred_label == torch.cuda.LongTensor(label)).sum().cpu().numpy())\n",
    "        total_num += len(label)\n",
    "        \n",
    "    acc_valid = correct_num / total_num\n",
    "    \n",
    "    training_loss_mean = np.mean(training_loss_list)\n",
    "    testing_loss_mean = np.mean(testing_loss_list)\n",
    "    validation_loss_mean = np.mean(validation_loss_list)\n",
    "    \n",
    "    print(datetime.datetime.now().time())\n",
    "    print('#{:03d} [Train: {:0.3f}] [Test: {:0.3f}] [Valid: {:0.3f}]'.format(epoch, training_loss_mean, testing_loss_mean, validation_loss_mean))\n",
    "    print('#{:03d} [Train: {:0.3f}] [Test: {:0.3f}] [Valid: {:0.3f}]'.format(epoch, acc_train, acc_test, acc_valid))\n",
    "    \n",
    "    writer.add_scalar('Loss/Train', training_loss_mean, epoch)\n",
    "    writer.add_scalar('Loss/Test', testing_loss_mean, epoch)\n",
    "    writer.add_scalar('Loss/Valid', validation_loss_mean, epoch)\n",
    "    writer.add_scalar('Acc/Train', acc_train, epoch)\n",
    "    writer.add_scalar('Acc/Test', acc_test, epoch)\n",
    "    writer.add_scalar('Acc/Valid', acc_valid, epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = model(torch.cuda.FloatTensor(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor(batch).unsqueeze_(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_tensor = torch.tensor(batch).to(device).float()\n",
    "# input_tensor = input_tensor.transpose(1, 2)\n",
    "# model(input_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for batch, label_list in batch_generator:\n",
    "#     print(batch.shape[0])\n",
    "#     plt.figure(figsize=(5, 1))\n",
    "#     plt.plot(label_list)\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.figure(figsize=(6, 18))\n",
    "# #     plt.imshow(batch[0], aspect='auto')\n",
    "#     plt.imshow(batch[0])\n",
    "#     plt.show()\n",
    "    \n",
    "#     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
